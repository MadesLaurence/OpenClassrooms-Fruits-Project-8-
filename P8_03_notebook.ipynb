{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective\n",
    "Set-up a first big data architecture using AWS products (Mobile application with a fruit pictures classifier engine)\n",
    "\n",
    "# Data\n",
    "Link to upload data: https://www.kaggle.com/moltean/fruits\n",
    "\n",
    "# Table of contents <a class=\"anchor\" id=\"chapter0\"></a> \n",
    "* [Preparation](#chapter1)\n",
    "    * [Import packages](#sub1_1)\n",
    "    * [Declare constants](#sub1_2)\n",
    "    * [Get picture information](#sub1_3)\n",
    "    * [Explore picture information](#sub1_4)\n",
    "    * [Get class information](#sub1_5) \n",
    "    * [Target label encoding](#sub1_6)\n",
    "* [Feature engineering](#chapter3)\n",
    "    * [Generate descriptors on Training dataset](#sub3_1)\n",
    "    * [Cluster's descriptors](#sub3_2)\n",
    "    * [Compute frequency histogram on clusters' descriptors](#sub3_3)\n",
    "    * [Reduce dimension with PCA](#sub3_4)\n",
    "* [Modelling](#chapter4)\n",
    "    * [Train a KNN model](#sub4_1)\n",
    "    * [Check learning curve](#sub4_2)\n",
    "    * [Predict and compare prediction to reality on Test dataset](#sub4_3)\n",
    "    * [Predict and compare prediction to reality on Validation dataset](#sub4_4)\n",
    "* [Go to End](#chapter100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation <a class=\"anchor\" id=\"chapter1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d632b08c-d252-4238-b496-e2c6edebec4b",
    "_uuid": "eb13bf76d4e1e60d0703856ec391cdc2c5bdf1fb"
   },
   "source": [
    "## Import packages <a class=\"anchor\" id=\"sub1_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import P8_02_module as MyMod\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "\n",
    "from cv2 import cv2\n",
    "import PIL\n",
    "from PIL import Image, ImageDraw, ImageOps, ImageFilter\n",
    "\n",
    "from sklearn import cluster\n",
    "from sklearn import decomposition\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import findspark\n",
    "\n",
    "from pyspark import SparkContext\n",
    "\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare constants <a class=\"anchor\" id=\"sub1_2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample volume limitations\n",
    "#GET_PICTURES_SAMPLE_SIZE = 50\n",
    "GET_PICTURES_NB_PER_CLASS = 2\n",
    "#TRAINING_SAMPLE_SIZE = 5000\n",
    "#TEST_SAMPLE_SIZE = 5000\n",
    "#VALIDATION_SAMPLE_SIZE = 5000\n",
    "\n",
    "# KMeans hyper-param\n",
    "KMEANS_N_CLUSTERS = 90\n",
    "\n",
    "# Pictures repository\n",
    "#PERSO_REP = \"C:\\\\Users\\\\BNP Leasing\\\\3D Objects\\\\Soutenance P8\\\\fruits-perso\\\\\"\n",
    "#PROJECT_REP = \"C:\\\\Users\\\\BNP Leasing\\\\3D Objects\\\\Soutenance P8\\\\fruits-360-original-size\\\\\"\n",
    "\n",
    "BUCKET_NAME = \"moncompartimentamoi\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get picture information <a class=\"anchor\" id=\"sub1_3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2.1\n"
     ]
    }
   ],
   "source": [
    "# For AWS deb________\n",
    "# Laurence: Ã  commenter\n",
    "findspark.init(\"C:\\spark\\spark-3.2.1-bin-hadoop3.2\")\n",
    "\n",
    "# Instantiate a SparkContext\n",
    "sc = SparkContext()\n",
    "\n",
    "print(sc.version)\n",
    "\n",
    "# Instantiate S3 client\n",
    "s3_client = boto3.client('s3', region_name='eu-west-3')\n",
    "\n",
    "s3_resource = boto3.resource('s3')\n",
    "\n",
    "s3_bucket = s3_resource.Bucket(BUCKET_NAME)\n",
    "\n",
    "# For AWS fin________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FullFileName</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Target</th>\n",
       "      <th>Picture</th>\n",
       "      <th>FileSize (in KB)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../fruits-360-original-size/Test/apple_6/r0_10...</td>\n",
       "      <td>Test</td>\n",
       "      <td>apple_6</td>\n",
       "      <td>r0_103.jpg</td>\n",
       "      <td>15.641602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../fruits-360-original-size/Test/apple_6/r0_10...</td>\n",
       "      <td>Test</td>\n",
       "      <td>apple_6</td>\n",
       "      <td>r0_107.jpg</td>\n",
       "      <td>15.830078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../fruits-360-original-size/Test/apple_braebur...</td>\n",
       "      <td>Test</td>\n",
       "      <td>apple_braeburn_1</td>\n",
       "      <td>r0_103.jpg</td>\n",
       "      <td>37.476562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../fruits-360-original-size/Test/apple_braebur...</td>\n",
       "      <td>Test</td>\n",
       "      <td>apple_braeburn_1</td>\n",
       "      <td>r0_107.jpg</td>\n",
       "      <td>37.428711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../fruits-360-original-size/Test/apple_crimson...</td>\n",
       "      <td>Test</td>\n",
       "      <td>apple_crimson_snow_1</td>\n",
       "      <td>r0_103.jpg</td>\n",
       "      <td>59.035156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>../fruits-360-original-size/Test/apple_crimson...</td>\n",
       "      <td>Test</td>\n",
       "      <td>apple_crimson_snow_1</td>\n",
       "      <td>r0_107.jpg</td>\n",
       "      <td>58.818359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>../fruits-360-original-size/Test/apple_golden_...</td>\n",
       "      <td>Test</td>\n",
       "      <td>apple_golden_1</td>\n",
       "      <td>r0_103.jpg</td>\n",
       "      <td>39.104492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>../fruits-360-original-size/Test/apple_golden_...</td>\n",
       "      <td>Test</td>\n",
       "      <td>apple_golden_1</td>\n",
       "      <td>r0_107.jpg</td>\n",
       "      <td>40.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>../fruits-360-original-size/Test/apple_golden_...</td>\n",
       "      <td>Test</td>\n",
       "      <td>apple_golden_2</td>\n",
       "      <td>r0_103.jpg</td>\n",
       "      <td>32.066406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>../fruits-360-original-size/Test/apple_golden_...</td>\n",
       "      <td>Test</td>\n",
       "      <td>apple_golden_2</td>\n",
       "      <td>r0_107.jpg</td>\n",
       "      <td>32.089844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>../fruits-360-original-size/Test/apple_golden_...</td>\n",
       "      <td>Test</td>\n",
       "      <td>apple_golden_3</td>\n",
       "      <td>r0_103.jpg</td>\n",
       "      <td>31.417969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>../fruits-360-original-size/Test/apple_golden_...</td>\n",
       "      <td>Test</td>\n",
       "      <td>apple_golden_3</td>\n",
       "      <td>r0_107.jpg</td>\n",
       "      <td>31.148438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>../fruits-360-original-size/Test/apple_granny_...</td>\n",
       "      <td>Test</td>\n",
       "      <td>apple_granny_smith_1</td>\n",
       "      <td>r0_103.jpg</td>\n",
       "      <td>37.783203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>../fruits-360-original-size/Test/apple_granny_...</td>\n",
       "      <td>Test</td>\n",
       "      <td>apple_granny_smith_1</td>\n",
       "      <td>r0_107.jpg</td>\n",
       "      <td>38.379883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>../fruits-360-original-size/Test/apple_hit_1/r...</td>\n",
       "      <td>Test</td>\n",
       "      <td>apple_hit_1</td>\n",
       "      <td>r0_103.jpg</td>\n",
       "      <td>118.681641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>../fruits-360-original-size/Test/apple_hit_1/r...</td>\n",
       "      <td>Test</td>\n",
       "      <td>apple_hit_1</td>\n",
       "      <td>r0_107.jpg</td>\n",
       "      <td>120.619141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>../fruits-360-original-size/Test/apple_pink_la...</td>\n",
       "      <td>Test</td>\n",
       "      <td>apple_pink_lady_1</td>\n",
       "      <td>r0_103.jpg</td>\n",
       "      <td>36.791016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>../fruits-360-original-size/Test/apple_pink_la...</td>\n",
       "      <td>Test</td>\n",
       "      <td>apple_pink_lady_1</td>\n",
       "      <td>r0_107.jpg</td>\n",
       "      <td>37.436523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>../fruits-360-original-size/Test/apple_red_1/r...</td>\n",
       "      <td>Test</td>\n",
       "      <td>apple_red_1</td>\n",
       "      <td>r0_103.jpg</td>\n",
       "      <td>44.325195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>../fruits-360-original-size/Test/apple_red_1/r...</td>\n",
       "      <td>Test</td>\n",
       "      <td>apple_red_1</td>\n",
       "      <td>r0_107.jpg</td>\n",
       "      <td>44.181641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         FullFileName Dataset  \\\n",
       "0   ../fruits-360-original-size/Test/apple_6/r0_10...    Test   \n",
       "1   ../fruits-360-original-size/Test/apple_6/r0_10...    Test   \n",
       "2   ../fruits-360-original-size/Test/apple_braebur...    Test   \n",
       "3   ../fruits-360-original-size/Test/apple_braebur...    Test   \n",
       "4   ../fruits-360-original-size/Test/apple_crimson...    Test   \n",
       "5   ../fruits-360-original-size/Test/apple_crimson...    Test   \n",
       "6   ../fruits-360-original-size/Test/apple_golden_...    Test   \n",
       "7   ../fruits-360-original-size/Test/apple_golden_...    Test   \n",
       "8   ../fruits-360-original-size/Test/apple_golden_...    Test   \n",
       "9   ../fruits-360-original-size/Test/apple_golden_...    Test   \n",
       "10  ../fruits-360-original-size/Test/apple_golden_...    Test   \n",
       "11  ../fruits-360-original-size/Test/apple_golden_...    Test   \n",
       "12  ../fruits-360-original-size/Test/apple_granny_...    Test   \n",
       "13  ../fruits-360-original-size/Test/apple_granny_...    Test   \n",
       "14  ../fruits-360-original-size/Test/apple_hit_1/r...    Test   \n",
       "15  ../fruits-360-original-size/Test/apple_hit_1/r...    Test   \n",
       "16  ../fruits-360-original-size/Test/apple_pink_la...    Test   \n",
       "17  ../fruits-360-original-size/Test/apple_pink_la...    Test   \n",
       "18  ../fruits-360-original-size/Test/apple_red_1/r...    Test   \n",
       "19  ../fruits-360-original-size/Test/apple_red_1/r...    Test   \n",
       "\n",
       "                  Target     Picture  FileSize (in KB)  \n",
       "0                apple_6  r0_103.jpg         15.641602  \n",
       "1                apple_6  r0_107.jpg         15.830078  \n",
       "2       apple_braeburn_1  r0_103.jpg         37.476562  \n",
       "3       apple_braeburn_1  r0_107.jpg         37.428711  \n",
       "4   apple_crimson_snow_1  r0_103.jpg         59.035156  \n",
       "5   apple_crimson_snow_1  r0_107.jpg         58.818359  \n",
       "6         apple_golden_1  r0_103.jpg         39.104492  \n",
       "7         apple_golden_1  r0_107.jpg         40.859375  \n",
       "8         apple_golden_2  r0_103.jpg         32.066406  \n",
       "9         apple_golden_2  r0_107.jpg         32.089844  \n",
       "10        apple_golden_3  r0_103.jpg         31.417969  \n",
       "11        apple_golden_3  r0_107.jpg         31.148438  \n",
       "12  apple_granny_smith_1  r0_103.jpg         37.783203  \n",
       "13  apple_granny_smith_1  r0_107.jpg         38.379883  \n",
       "14           apple_hit_1  r0_103.jpg        118.681641  \n",
       "15           apple_hit_1  r0_107.jpg        120.619141  \n",
       "16     apple_pink_lady_1  r0_103.jpg         36.791016  \n",
       "17     apple_pink_lady_1  r0_107.jpg         37.436523  \n",
       "18           apple_red_1  r0_103.jpg         44.325195  \n",
       "19           apple_red_1  r0_107.jpg         44.181641  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build Dataframe and transfer pictures from local repository to AWS S3\n",
    "\n",
    "path = '../fruits-360-original-size/'\n",
    "\n",
    "# Get Dataset names, Target class names and Picture names\n",
    "df_main = pd.DataFrame(columns = ['FullFileName', 'Dataset', 'Target', 'Picture', 'FileSize (in KB)']) \n",
    "target_prec = \"\"\n",
    "\n",
    "for file in glob.iglob(path+'**/*.jpg', recursive = True):\n",
    "    \n",
    "    lst = file.split('\\\\')\n",
    "    \n",
    "    # Limit number of pictures per class(GET_PICTURES_NB_PER_CLASS)\n",
    "    if lst[2] == target_prec: \n",
    "        i += 1\n",
    "    else:\n",
    "        i = 0\n",
    "    target_prec = lst[2]\n",
    "    \n",
    "    if (lst[1] == 'Training' and i < 2*GET_PICTURES_NB_PER_CLASS) or \\\n",
    "                    (lst[1] != 'Training' and i < GET_PICTURES_NB_PER_CLASS):     \n",
    "        \n",
    "        # update DataFrame\n",
    "        lst.append(os.path.getsize(file) / 1024)  # in KBytes    \n",
    "        lst[0] = lst[0] + \"/\" + lst[1] + \"/\" + lst[2] + \"/\" + lst[3]\n",
    "        df_main.loc[len(df_main)] = lst\n",
    "                \n",
    "        # For AWS deb________\n",
    "        # upload the image in the AWS S3 bucket  \n",
    "        s3_client.upload_file(lst[0], BUCKET_NAME, lst[1]+\"/\"+lst[2]+\"/\"+lst[3])\n",
    "        # For AWS fin________\n",
    "        \n",
    "df_main.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FullFileName</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Target</th>\n",
       "      <th>Picture</th>\n",
       "      <th>FileSize (in KB)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../fruits-360-original-size/Test/apple_6/r0_10...</td>\n",
       "      <td>Test</td>\n",
       "      <td>apple_6</td>\n",
       "      <td>r0_103.jpg</td>\n",
       "      <td>15.641602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../fruits-360-original-size/Test/apple_6/r0_10...</td>\n",
       "      <td>Test</td>\n",
       "      <td>apple_6</td>\n",
       "      <td>r0_107.jpg</td>\n",
       "      <td>15.830078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../fruits-360-original-size/Test/apple_braebur...</td>\n",
       "      <td>Test</td>\n",
       "      <td>apple_braeburn_1</td>\n",
       "      <td>r0_103.jpg</td>\n",
       "      <td>37.476562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../fruits-360-original-size/Test/apple_braebur...</td>\n",
       "      <td>Test</td>\n",
       "      <td>apple_braeburn_1</td>\n",
       "      <td>r0_107.jpg</td>\n",
       "      <td>37.428711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../fruits-360-original-size/Test/apple_crimson...</td>\n",
       "      <td>Test</td>\n",
       "      <td>apple_crimson_snow_1</td>\n",
       "      <td>r0_103.jpg</td>\n",
       "      <td>59.035156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>../fruits-360-original-size/Validation/pear_3/...</td>\n",
       "      <td>Validation</td>\n",
       "      <td>pear_3</td>\n",
       "      <td>r0_101.jpg</td>\n",
       "      <td>71.865234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>../fruits-360-original-size/Validation/zucchin...</td>\n",
       "      <td>Validation</td>\n",
       "      <td>zucchini_1</td>\n",
       "      <td>r0_1.jpg</td>\n",
       "      <td>43.950195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>../fruits-360-original-size/Validation/zucchin...</td>\n",
       "      <td>Validation</td>\n",
       "      <td>zucchini_1</td>\n",
       "      <td>r0_101.jpg</td>\n",
       "      <td>50.963867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>../fruits-360-original-size/Validation/zucchin...</td>\n",
       "      <td>Validation</td>\n",
       "      <td>zucchini_dark_1</td>\n",
       "      <td>r0_1.jpg</td>\n",
       "      <td>33.743164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>../fruits-360-original-size/Validation/zucchin...</td>\n",
       "      <td>Validation</td>\n",
       "      <td>zucchini_dark_1</td>\n",
       "      <td>r0_101.jpg</td>\n",
       "      <td>37.641602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows Ã 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          FullFileName     Dataset  \\\n",
       "0    ../fruits-360-original-size/Test/apple_6/r0_10...        Test   \n",
       "1    ../fruits-360-original-size/Test/apple_6/r0_10...        Test   \n",
       "2    ../fruits-360-original-size/Test/apple_braebur...        Test   \n",
       "3    ../fruits-360-original-size/Test/apple_braebur...        Test   \n",
       "4    ../fruits-360-original-size/Test/apple_crimson...        Test   \n",
       "..                                                 ...         ...   \n",
       "187  ../fruits-360-original-size/Validation/pear_3/...  Validation   \n",
       "188  ../fruits-360-original-size/Validation/zucchin...  Validation   \n",
       "189  ../fruits-360-original-size/Validation/zucchin...  Validation   \n",
       "190  ../fruits-360-original-size/Validation/zucchin...  Validation   \n",
       "191  ../fruits-360-original-size/Validation/zucchin...  Validation   \n",
       "\n",
       "                   Target     Picture  FileSize (in KB)  \n",
       "0                 apple_6  r0_103.jpg         15.641602  \n",
       "1                 apple_6  r0_107.jpg         15.830078  \n",
       "2        apple_braeburn_1  r0_103.jpg         37.476562  \n",
       "3        apple_braeburn_1  r0_107.jpg         37.428711  \n",
       "4    apple_crimson_snow_1  r0_103.jpg         59.035156  \n",
       "..                    ...         ...               ...  \n",
       "187                pear_3  r0_101.jpg         71.865234  \n",
       "188            zucchini_1    r0_1.jpg         43.950195  \n",
       "189            zucchini_1  r0_101.jpg         50.963867  \n",
       "190       zucchini_dark_1    r0_1.jpg         33.743164  \n",
       "191       zucchini_dark_1  r0_101.jpg         37.641602  \n",
       "\n",
       "[192 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build full file names\n",
    "#Laurence: df_main['FullFileName'] = df_main['FullFileName']+'/'+df_main['Dataset']+'/'+df_main['Target']+'/'+df_main['Picture']  \n",
    "df_main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore picture information <a class=\"anchor\" id=\"sub1_4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess volumes and modalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " > 12 455 pictures, 24 target classes, 3 datasets  \n",
    " > 958 picture names mean that some pictures have the same name and are not classified in the same repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count pictures by target class and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(df_main.groupby(['Target', 'Dataset'])['Picture'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count pictures by target class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(df_main.groupby(['Target'])['Picture'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count dataset modality by picture name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset_mod = pd.DataFrame(df_main.groupby(['Picture'])['Dataset'].nunique())\n",
    "df_dataset_mod.rename(columns={'Dataset':'Dataset_mod'}, inplace=True)\n",
    "len(df_dataset_mod[df_dataset_mod['Dataset_mod'] > 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> No file with the same name in the different datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count target class modality by picture name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_target_mod = pd.DataFrame(df_main.groupby(['Picture'])['Target'].nunique())\n",
    "df_target_mod.rename(columns={'Target':'Target_mod'}, inplace=True)\n",
    "df_target_mod[df_target_mod['Target_mod'] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target_mod = df_target_mod.reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(df_target_mod.groupby(['Target_mod'])['Picture'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " > many files with the same name in the different target classes   \n",
    " > for instance, 156 files have the same name and appear in 24 different target class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_main[df_main['Picture'] == 'r0_0.jpg'][['Picture', 'Target', 'Dataset']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pict = Image.open(df_main['FullFileName'].iloc[20])\n",
    "plt.imshow(pict)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pict = Image.open(df_main['FullFileName'].iloc[40])\n",
    "plt.imshow(pict)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " > File name format: r?_image_index.jpg (e.g. r0_31.jpg or r1_12.jpg)  \n",
    " > \"r?\" stands for rotation axis (first one is r0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distinguish rotation axis and index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Laurence: supprimler les FutureWarning\n",
    "df_main[\"Rotation\"], df_main[\"Index\"] = df_main[\"Picture\"].str.split(\"_\", 1).str\n",
    "df_main[\"Rotation\"] = df_main[\"Rotation\"].str.replace('r','')\n",
    "df_main[\"Index\"] = df_main[\"Index\"].str.replace('.jpg','')\n",
    "df_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(df_main[\"Rotation\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pict = Image.open(df_main['FullFileName'].iloc[df_main[df_main['Rotation'] == '0'].head(1).index[0]])\n",
    "plt.imshow(pict)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''pict = Image.open(df_main['FullFileName'].iloc[df_main[df_main['Rotation'] == '1'].head(1).index[0]])\n",
    "plt.imshow(pict)\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''pict = Image.open(df_main['FullFileName'].iloc[df_main[df_main['Rotation'] == '2'].head(1).index[0]])\n",
    "plt.imshow(pict)\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " > 0 - queue top or down > rotation around the z-axis  \n",
    " > 1 - queue behind or ahead > rotation around the x-axis  \n",
    " > 2 - queue left or right > rotation around the y-axis  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target class count distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribution(df_in, dataset):\n",
    "    \n",
    "    df = df_in.copy()\n",
    "    \n",
    "    if dataset in ['Training', 'Test', 'Validation']:\n",
    "        df.drop(df[df['Dataset'] != dataset].index, inplace=True)\n",
    "    elif dataset != '*':\n",
    "        print(\"dataset argument should be 'Training', 'Test', 'Validation' or '*'\")\n",
    "        return -1\n",
    "        \n",
    "    df_distrib = pd.DataFrame(df.groupby(['Target'])['Picture'].count())\n",
    "    df_distrib.reset_index(drop=False, inplace=True)\n",
    "    df_distrib.rename(columns={'Picture':'Picture count', 'Target':'Class'}, inplace=True)\n",
    "    df_distrib = df_distrib.sort_values(by='Class', ascending=False)    \n",
    "\n",
    "    if len(df_distrib) == 0: return -1\n",
    "    \n",
    "    df_distrib.plot.barh(x='Class', y='Picture count', figsize=(12, 10))    \n",
    "    \n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ret = distribution(df_main, 'Training')\n",
    "ret = distribution(df_main, 'Test')\n",
    "ret = distribution(df_main, 'Validation')\n",
    "ret = distribution(df_main, '*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target class filesize average distribution  \n",
    "Logitech C920 camera and dedicated algorithm which extract the fruit from the background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(df_main.groupby('Target')['FileSize (in KB)'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df_main.groupby('Dataset')['FileSize (in KB)'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main['FileSize (in KB)'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get class information <a class=\"anchor\" id=\"sub1_5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = '../fruits-360-original-size/Meta/'\n",
    "\n",
    "df_class_add = pd.DataFrame(columns = ['PathName', 'Target', 'TxtName'])\n",
    "df_meta = pd.DataFrame(columns = ['Flag', 'Value'])\n",
    "\n",
    "for file in glob.iglob(path+'**/info.txt', recursive = True):\n",
    "    \n",
    "    df_meta_add = pd.read_csv(file, sep=\"=\", names=['Flag', 'Value'])\n",
    "        \n",
    "    df_class_add.loc[0] = file.split('\\\\')   \n",
    "        \n",
    "    df_meta = pd.concat([df_class_add.join(df_meta_add, how='cross'), df_meta])\n",
    "\n",
    "del df_class_add, df_meta_add\n",
    "\n",
    "df_meta.drop(columns=['PathName', 'TxtName'], inplace=True)\n",
    "df_meta = df_meta.sort_values(['Target', 'Flag'], ascending=True)\n",
    "df_meta.reset_index(drop=True, inplace=True)\n",
    "df_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta['Flag'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(df_meta['Flag'].unique(), columns=['Flag']).sort_values(by='Flag')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target label encoding  <a class=\"anchor\" id=\"sub1_6\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_main, df_target_mapping = MyMod.encode_LabelEncoder(df_main, 'Target')\n",
    "df_main.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta, df_target_mapping = MyMod.encode_LabelEncoder(df_meta, 'Target')\n",
    "df_meta.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_target_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering <a class=\"anchor\" id=\"chapter3\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate descriptors on Training dataset <a class=\"anchor\" id=\"sub3_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def dataset_reduction(df, SAMPLE_SIZE):\n",
    "    # Initiate index\n",
    "    ind_sample = np.arange(len(df))\n",
    "    # Shuffle\n",
    "    ind_sample = shuffle(ind_sample, random_state=42)\n",
    "    # Select SAMPLE_SIZE first index  \n",
    "    ind_sample = ind_sample[:SAMPLE_SIZE]\n",
    "    \n",
    "    # Check balanced dataset over 'Target', 'Rotation' features\n",
    "    # Prepare resulting dataframe\n",
    "    df_ret = df.iloc[ind_sample] \n",
    "    # Reset index\n",
    "    df_ret.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return df_ret'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main_training = df_main[df_main['Dataset'] == 'Training']\n",
    "#df_main_training = dataset_reduction(df_main_training, TRAINING_SAMPLE_SIZE)\n",
    "df_main_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def desc_extraction(df_main_training):\n",
    "    \n",
    "    # Create SIFT descriptor\n",
    "    sift = cv2.SIFT_create()\n",
    "\n",
    "    # Initiate the resulting dataframe for key points descriptors\n",
    "    df_kpdesc_training = pd.DataFrame()\n",
    "\n",
    "    for pict_num in range(len(df_main_training)):\n",
    "\n",
    "        # Print treatment progress each 100 pictures\n",
    "        if pict_num%100 == 0 : print(pict_num)\n",
    "\n",
    "        # Open the picture\n",
    "        pict = Image.open(df_main_training['FullFileName'].iloc[pict_num])\n",
    "\n",
    "        # Compute key points and picture descriptors\n",
    "        # descript: numpy array with one line by interest point, 128 columns\n",
    "        keypoints, descript = sift.detectAndCompute(np.array(pict), None)\n",
    "\n",
    "        # Enrich df_kpdesc_training with FullFileName\n",
    "        df_pict_name = df_main_training[df_main_training.index == pict_num][['FullFileName']]        \n",
    "        df_kpdesc = df_pict_name.merge(pd.DataFrame(descript), how='cross')\n",
    "\n",
    "        # Concatenate new samples to the resulting dataframe\n",
    "        df_kpdesc_training = pd.concat([df_kpdesc_training, df_kpdesc])\n",
    "\n",
    "    # Reset indexation\n",
    "    df_kpdesc_training.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return df_kpdesc_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save starting time\n",
    "time_start=time.time()\n",
    "\n",
    "df_kpdesc_training = desc_extraction(df_main_training)\n",
    "\n",
    "# Compute time elapse\n",
    "elapse_s = round(time.time()-time_start, 0)\n",
    "elapse_m = round(elapse_s / 60, 2)\n",
    "print()\n",
    "print('Time elapse with SIFT descriptor : {} seconds ({} minutes)'.format(elapse_s, elapse_m))\n",
    "\n",
    "print()\n",
    "print(\"Descriptor dataframe shape : \", df_kpdesc_training.shape)\n",
    "\n",
    "df_kpdesc_training.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extration des descripteurs : jpg sur S3 > descripteurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Though SparkContext used to be an entry point prior to 2.0, it is not completely replaced with SparkSession,\n",
    "#many features of SparkContext are still available and used in Spark 2.0 and later. \n",
    "#You should also know that SparkSession internally creates SparkConfig and SparkContext with the configuration \n",
    "#provided with SparkSession."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fait plus haut\n",
    "\n",
    "#BUCKET_NAME = \"moncompartimentamoi\"\n",
    "\n",
    "#sc = SparkContext()\n",
    "#print(sc.version)\n",
    "\n",
    "#s3_client = boto3.client('s3', region_name='eu-west-3')\n",
    "#s3_client.upload_file(lst[0], BUCKET_NAME, lst[1]+\"/\"+lst[2]+\"/\"+lst[3])\n",
    "\n",
    "#s3_resource = boto3.resource('s3')\n",
    "#s3_bucket = s3_resource.Bucket(BUCKET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_image_from_s3(key):\n",
    "    \"\"\"Load image file from s3.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    key : string           Path in s3\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np array               Image array\n",
    "    \"\"\"   \n",
    "    #object = s3_bucket.Object(key)\n",
    "    #response = object.get()\n",
    "    #file_stream = response['Body']    \n",
    "    #im = Image.open(file_stream)\n",
    "    \n",
    "    return np.array(Image.open(s3_bucket.Object(key).get()['Body']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"reprendre lÃ \"  \n",
    "Chargement et copie dâobjets Ã  lâaide dâun chargement partitionnÃ©?  \n",
    "Multithreading or multiprocessing with sessions?  \n",
    "How to read image file from S3 bucket directly into memory?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MonPrefixe/MonRapport/20220301-20220401/20220308T142121Z/MonRapport-00001.csv.zip\n",
      "MonPrefixe/MonRapport/20220301-20220401/20220308T142121Z/MonRapport-Manifest.json\n",
      "MonPrefixe/MonRapport/20220301-20220401/MonRapport-Manifest.json\n",
      "Test/apple_6/r0_103.jpg\n",
      "Test/apple_6/r0_103.jpg\n",
      "Test/apple_6/r0_107.jpg\n",
      "Test/apple_6/r0_107.jpg\n",
      "Test/apple_braeburn_1/r0_103.jpg\n",
      "Test/apple_braeburn_1/r0_103.jpg\n",
      "Test/apple_braeburn_1/r0_107.jpg\n",
      "Test/apple_braeburn_1/r0_107.jpg\n",
      "Test/apple_crimson_snow_1/r0_103.jpg\n",
      "Test/apple_crimson_snow_1/r0_103.jpg\n",
      "Test/apple_crimson_snow_1/r0_107.jpg\n",
      "Test/apple_crimson_snow_1/r0_107.jpg\n",
      "Test/apple_golden_1/r0_103.jpg\n",
      "Test/apple_golden_1/r0_103.jpg\n",
      "Test/apple_golden_1/r0_107.jpg\n",
      "Test/apple_golden_1/r0_107.jpg\n",
      "Test/apple_golden_2/r0_103.jpg\n",
      "Test/apple_golden_2/r0_103.jpg\n",
      "Test/apple_golden_2/r0_107.jpg\n",
      "Test/apple_golden_2/r0_107.jpg\n",
      "Test/apple_golden_3/r0_103.jpg\n",
      "Test/apple_golden_3/r0_103.jpg\n",
      "Test/apple_golden_3/r0_107.jpg\n",
      "Test/apple_golden_3/r0_107.jpg\n",
      "Test/apple_granny_smith_1/r0_103.jpg\n",
      "Test/apple_granny_smith_1/r0_103.jpg\n",
      "Test/apple_granny_smith_1/r0_107.jpg\n",
      "Test/apple_granny_smith_1/r0_107.jpg\n",
      "Test/apple_hit_1/r0_103.jpg\n",
      "Test/apple_hit_1/r0_103.jpg\n",
      "Test/apple_hit_1/r0_107.jpg\n",
      "Test/apple_hit_1/r0_107.jpg\n",
      "Test/apple_pink_lady_1/r0_103.jpg\n",
      "Test/apple_pink_lady_1/r0_103.jpg\n",
      "Test/apple_pink_lady_1/r0_107.jpg\n",
      "Test/apple_pink_lady_1/r0_107.jpg\n",
      "Test/apple_red_1/r0_103.jpg\n",
      "Test/apple_red_1/r0_103.jpg\n",
      "Test/apple_red_1/r0_107.jpg\n",
      "Test/apple_red_1/r0_107.jpg\n",
      "Test/apple_red_2/r0_103.jpg\n",
      "Test/apple_red_2/r0_103.jpg\n",
      "Test/apple_red_2/r0_107.jpg\n",
      "Test/apple_red_2/r0_107.jpg\n",
      "Test/apple_red_3/r0_103.jpg\n",
      "Test/apple_red_3/r0_103.jpg\n",
      "Test/apple_red_3/r0_107.jpg\n",
      "Test/apple_red_3/r0_107.jpg\n",
      "Test/apple_red_delicios_1/r0_103.jpg\n",
      "Test/apple_red_delicios_1/r0_103.jpg\n",
      "Test/apple_red_delicios_1/r0_107.jpg\n",
      "Test/apple_red_delicios_1/r0_107.jpg\n",
      "Test/apple_red_yellow_1/r0_103.jpg\n",
      "Test/apple_red_yellow_1/r0_103.jpg\n",
      "Test/apple_red_yellow_1/r0_107.jpg\n",
      "Test/apple_red_yellow_1/r0_107.jpg\n",
      "Test/apple_rotten_1/r0_103.jpg\n",
      "Test/apple_rotten_1/r0_103.jpg\n",
      "Test/apple_rotten_1/r0_107.jpg\n",
      "Test/apple_rotten_1/r0_107.jpg\n",
      "Test/cabbage_white_1/r0_103.jpg\n",
      "Test/cabbage_white_1/r0_103.jpg\n",
      "Test/cabbage_white_1/r0_107.jpg\n",
      "Test/cabbage_white_1/r0_107.jpg\n",
      "Test/carrot_1/r0_103.jpg\n",
      "Test/carrot_1/r0_103.jpg\n",
      "Test/carrot_1/r0_107.jpg\n",
      "Test/carrot_1/r0_107.jpg\n",
      "Test/cucumber_1/r0_103.jpg\n",
      "Test/cucumber_1/r0_103.jpg\n",
      "Test/cucumber_1/r0_107.jpg\n",
      "Test/cucumber_1/r0_107.jpg\n",
      "Test/cucumber_3/r0_103.jpg\n",
      "Test/cucumber_3/r0_103.jpg\n",
      "Test/cucumber_3/r0_107.jpg\n",
      "Test/cucumber_3/r0_107.jpg\n",
      "Test/eggplant_violet_1/r0_103.jpg\n",
      "Test/eggplant_violet_1/r0_103.jpg\n",
      "Test/eggplant_violet_1/r0_107.jpg\n",
      "Test/eggplant_violet_1/r0_107.jpg\n",
      "Test/pear_1/r0_103.jpg\n",
      "Test/pear_1/r0_103.jpg\n",
      "Test/pear_1/r0_107.jpg\n",
      "Test/pear_1/r0_107.jpg\n",
      "Test/pear_3/r0_103.jpg\n",
      "Test/pear_3/r0_103.jpg\n",
      "Test/pear_3/r0_107.jpg\n",
      "Test/pear_3/r0_107.jpg\n",
      "Test/zucchini_1/r0_103.jpg\n",
      "Test/zucchini_1/r0_103.jpg\n",
      "Test/zucchini_1/r0_107.jpg\n",
      "Test/zucchini_1/r0_107.jpg\n",
      "Test/zucchini_dark_1/r0_103.jpg\n",
      "Test/zucchini_dark_1/r0_103.jpg\n",
      "Test/zucchini_dark_1/r0_107.jpg\n",
      "Test/zucchini_dark_1/r0_107.jpg\n",
      "Training/apple_6/r0_0.jpg\n",
      "Training/apple_6/r0_0.jpg\n",
      "Training/apple_6/r0_10.jpg\n",
      "Training/apple_6/r0_10.jpg\n",
      "Training/apple_6/r0_100.jpg\n",
      "Training/apple_6/r0_100.jpg\n",
      "Training/apple_6/r0_102.jpg\n",
      "Training/apple_6/r0_102.jpg\n",
      "Training/apple_braeburn_1/r0_0.jpg\n",
      "Training/apple_braeburn_1/r0_0.jpg\n",
      "Training/apple_braeburn_1/r0_10.jpg\n",
      "Training/apple_braeburn_1/r0_10.jpg\n",
      "Training/apple_braeburn_1/r0_100.jpg\n",
      "Training/apple_braeburn_1/r0_100.jpg\n",
      "Training/apple_braeburn_1/r0_102.jpg\n",
      "Training/apple_braeburn_1/r0_102.jpg\n",
      "Training/apple_crimson_snow_1/r0_0.jpg\n",
      "Training/apple_crimson_snow_1/r0_0.jpg\n",
      "Training/apple_crimson_snow_1/r0_10.jpg\n",
      "Training/apple_crimson_snow_1/r0_10.jpg\n",
      "Training/apple_crimson_snow_1/r0_100.jpg\n",
      "Training/apple_crimson_snow_1/r0_100.jpg\n",
      "Training/apple_crimson_snow_1/r0_102.jpg\n",
      "Training/apple_crimson_snow_1/r0_102.jpg\n",
      "Training/apple_golden_1/r0_0.jpg\n",
      "Training/apple_golden_1/r0_0.jpg\n",
      "Training/apple_golden_1/r0_10.jpg\n",
      "Training/apple_golden_1/r0_10.jpg\n",
      "Training/apple_golden_1/r0_100.jpg\n",
      "Training/apple_golden_1/r0_100.jpg\n",
      "Training/apple_golden_1/r0_102.jpg\n",
      "Training/apple_golden_1/r0_102.jpg\n",
      "Training/apple_golden_2/r0_0.jpg\n",
      "Training/apple_golden_2/r0_0.jpg\n",
      "Training/apple_golden_2/r0_10.jpg\n",
      "Training/apple_golden_2/r0_10.jpg\n",
      "Training/apple_golden_2/r0_100.jpg\n",
      "Training/apple_golden_2/r0_100.jpg\n",
      "Training/apple_golden_2/r0_102.jpg\n",
      "Training/apple_golden_2/r0_102.jpg\n",
      "Training/apple_golden_3/r0_0.jpg\n",
      "Training/apple_golden_3/r0_0.jpg\n",
      "Training/apple_golden_3/r0_10.jpg\n",
      "Training/apple_golden_3/r0_10.jpg\n",
      "Training/apple_golden_3/r0_100.jpg\n",
      "Training/apple_golden_3/r0_100.jpg\n",
      "Training/apple_golden_3/r0_102.jpg\n",
      "Training/apple_golden_3/r0_102.jpg\n",
      "Training/apple_granny_smith_1/r0_0.jpg\n",
      "Training/apple_granny_smith_1/r0_0.jpg\n",
      "Training/apple_granny_smith_1/r0_10.jpg\n",
      "Training/apple_granny_smith_1/r0_10.jpg\n",
      "Training/apple_granny_smith_1/r0_100.jpg\n",
      "Training/apple_granny_smith_1/r0_100.jpg\n",
      "Training/apple_granny_smith_1/r0_102.jpg\n",
      "Training/apple_granny_smith_1/r0_102.jpg\n",
      "Training/apple_hit_1/r0_0.jpg\n",
      "Training/apple_hit_1/r0_0.jpg\n",
      "Training/apple_hit_1/r0_10.jpg\n",
      "Training/apple_hit_1/r0_10.jpg\n",
      "Training/apple_hit_1/r0_100.jpg\n",
      "Training/apple_hit_1/r0_100.jpg\n",
      "Training/apple_hit_1/r0_102.jpg\n",
      "Training/apple_hit_1/r0_102.jpg\n",
      "Training/apple_pink_lady_1/r0_0.jpg\n",
      "Training/apple_pink_lady_1/r0_0.jpg\n",
      "Training/apple_pink_lady_1/r0_10.jpg\n",
      "Training/apple_pink_lady_1/r0_10.jpg\n",
      "Training/apple_pink_lady_1/r0_100.jpg\n",
      "Training/apple_pink_lady_1/r0_100.jpg\n",
      "Training/apple_pink_lady_1/r0_102.jpg\n",
      "Training/apple_pink_lady_1/r0_102.jpg\n",
      "Training/apple_red_1/r0_0.jpg\n",
      "Training/apple_red_1/r0_0.jpg\n",
      "Training/apple_red_1/r0_10.jpg\n",
      "Training/apple_red_1/r0_10.jpg\n",
      "Training/apple_red_1/r0_100.jpg\n",
      "Training/apple_red_1/r0_100.jpg\n",
      "Training/apple_red_1/r0_102.jpg\n",
      "Training/apple_red_1/r0_102.jpg\n",
      "Training/apple_red_2/r0_0.jpg\n",
      "Training/apple_red_2/r0_0.jpg\n",
      "Training/apple_red_2/r0_10.jpg\n",
      "Training/apple_red_2/r0_10.jpg\n",
      "Training/apple_red_2/r0_100.jpg\n",
      "Training/apple_red_2/r0_100.jpg\n",
      "Training/apple_red_2/r0_102.jpg\n",
      "Training/apple_red_2/r0_102.jpg\n",
      "Training/apple_red_3/r0_0.jpg\n",
      "Training/apple_red_3/r0_0.jpg\n",
      "Training/apple_red_3/r0_10.jpg\n",
      "Training/apple_red_3/r0_10.jpg\n",
      "Training/apple_red_3/r0_100.jpg\n",
      "Training/apple_red_3/r0_100.jpg\n",
      "Training/apple_red_3/r0_102.jpg\n",
      "Training/apple_red_3/r0_102.jpg\n",
      "Training/apple_red_delicios_1/r0_0.jpg\n",
      "Training/apple_red_delicios_1/r0_0.jpg\n",
      "Training/apple_red_delicios_1/r0_10.jpg\n",
      "Training/apple_red_delicios_1/r0_10.jpg\n",
      "Training/apple_red_delicios_1/r0_100.jpg\n",
      "Training/apple_red_delicios_1/r0_100.jpg\n",
      "Training/apple_red_delicios_1/r0_102.jpg\n",
      "Training/apple_red_delicios_1/r0_102.jpg\n",
      "Training/apple_red_yellow_1/r0_0.jpg\n",
      "Training/apple_red_yellow_1/r0_0.jpg\n",
      "Training/apple_red_yellow_1/r0_10.jpg\n",
      "Training/apple_red_yellow_1/r0_10.jpg\n",
      "Training/apple_red_yellow_1/r0_100.jpg\n",
      "Training/apple_red_yellow_1/r0_100.jpg\n",
      "Training/apple_red_yellow_1/r0_102.jpg\n",
      "Training/apple_red_yellow_1/r0_102.jpg\n",
      "Training/apple_rotten_1/r0_0.jpg\n",
      "Training/apple_rotten_1/r0_0.jpg\n",
      "Training/apple_rotten_1/r0_10.jpg\n",
      "Training/apple_rotten_1/r0_10.jpg\n",
      "Training/apple_rotten_1/r0_100.jpg\n",
      "Training/apple_rotten_1/r0_100.jpg\n",
      "Training/apple_rotten_1/r0_102.jpg\n",
      "Training/apple_rotten_1/r0_102.jpg\n",
      "Training/cabbage_white_1/r0_0.jpg\n",
      "Training/cabbage_white_1/r0_0.jpg\n",
      "Training/cabbage_white_1/r0_10.jpg\n",
      "Training/cabbage_white_1/r0_10.jpg\n",
      "Training/cabbage_white_1/r0_100.jpg\n",
      "Training/cabbage_white_1/r0_100.jpg\n",
      "Training/cabbage_white_1/r0_102.jpg\n",
      "Training/cabbage_white_1/r0_102.jpg\n",
      "Training/carrot_1/r0_0.jpg\n",
      "Training/carrot_1/r0_0.jpg\n",
      "Training/carrot_1/r0_10.jpg\n",
      "Training/carrot_1/r0_10.jpg\n",
      "Training/carrot_1/r0_100.jpg\n",
      "Training/carrot_1/r0_100.jpg\n",
      "Training/carrot_1/r0_102.jpg\n",
      "Training/carrot_1/r0_102.jpg\n",
      "Training/cucumber_1/r0_0.jpg\n",
      "Training/cucumber_1/r0_0.jpg\n",
      "Training/cucumber_1/r0_10.jpg\n",
      "Training/cucumber_1/r0_10.jpg\n",
      "Training/cucumber_1/r0_100.jpg\n",
      "Training/cucumber_1/r0_100.jpg\n",
      "Training/cucumber_1/r0_102.jpg\n",
      "Training/cucumber_1/r0_102.jpg\n",
      "Training/cucumber_3/r0_0.jpg\n",
      "Training/cucumber_3/r0_0.jpg\n",
      "Training/cucumber_3/r0_10.jpg\n",
      "Training/cucumber_3/r0_10.jpg\n",
      "Training/cucumber_3/r0_100.jpg\n",
      "Training/cucumber_3/r0_100.jpg\n",
      "Training/cucumber_3/r0_102.jpg\n",
      "Training/cucumber_3/r0_102.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/eggplant_violet_1/r0_0.jpg\n",
      "Training/eggplant_violet_1/r0_0.jpg\n",
      "Training/eggplant_violet_1/r0_10.jpg\n",
      "Training/eggplant_violet_1/r0_10.jpg\n",
      "Training/eggplant_violet_1/r0_100.jpg\n",
      "Training/eggplant_violet_1/r0_100.jpg\n",
      "Training/eggplant_violet_1/r0_102.jpg\n",
      "Training/eggplant_violet_1/r0_102.jpg\n",
      "Training/pear_1/r0_0.jpg\n",
      "Training/pear_1/r0_0.jpg\n",
      "Training/pear_1/r0_10.jpg\n",
      "Training/pear_1/r0_10.jpg\n",
      "Training/pear_1/r0_100.jpg\n",
      "Training/pear_1/r0_100.jpg\n",
      "Training/pear_1/r0_102.jpg\n",
      "Training/pear_1/r0_102.jpg\n",
      "Training/pear_3/r0_0.jpg\n",
      "Training/pear_3/r0_0.jpg\n",
      "Training/pear_3/r0_10.jpg\n",
      "Training/pear_3/r0_10.jpg\n",
      "Training/pear_3/r0_100.jpg\n",
      "Training/pear_3/r0_100.jpg\n",
      "Training/pear_3/r0_102.jpg\n",
      "Training/pear_3/r0_102.jpg\n",
      "Training/zucchini_1/r0_0.jpg\n",
      "Training/zucchini_1/r0_0.jpg\n",
      "Training/zucchini_1/r0_10.jpg\n",
      "Training/zucchini_1/r0_10.jpg\n",
      "Training/zucchini_1/r0_100.jpg\n",
      "Training/zucchini_1/r0_100.jpg\n",
      "Training/zucchini_1/r0_102.jpg\n",
      "Training/zucchini_1/r0_102.jpg\n",
      "Training/zucchini_dark_1/r0_0.jpg\n",
      "Training/zucchini_dark_1/r0_0.jpg\n",
      "Training/zucchini_dark_1/r0_10.jpg\n",
      "Training/zucchini_dark_1/r0_10.jpg\n",
      "Training/zucchini_dark_1/r0_100.jpg\n",
      "Training/zucchini_dark_1/r0_100.jpg\n",
      "Training/zucchini_dark_1/r0_102.jpg\n",
      "Training/zucchini_dark_1/r0_102.jpg\n",
      "Validation/apple_6/r0_1.jpg\n",
      "Validation/apple_6/r0_1.jpg\n",
      "Validation/apple_6/r0_101.jpg\n",
      "Validation/apple_6/r0_101.jpg\n",
      "Validation/apple_braeburn_1/r0_1.jpg\n",
      "Validation/apple_braeburn_1/r0_1.jpg\n",
      "Validation/apple_braeburn_1/r0_101.jpg\n",
      "Validation/apple_braeburn_1/r0_101.jpg\n",
      "Validation/apple_crimson_snow_1/r0_1.jpg\n",
      "Validation/apple_crimson_snow_1/r0_1.jpg\n",
      "Validation/apple_crimson_snow_1/r0_101.jpg\n",
      "Validation/apple_crimson_snow_1/r0_101.jpg\n",
      "Validation/apple_golden_1/r0_1.jpg\n",
      "Validation/apple_golden_1/r0_1.jpg\n",
      "Validation/apple_golden_1/r0_101.jpg\n",
      "Validation/apple_golden_1/r0_101.jpg\n",
      "Validation/apple_golden_2/r0_1.jpg\n",
      "Validation/apple_golden_2/r0_1.jpg\n",
      "Validation/apple_golden_2/r0_101.jpg\n",
      "Validation/apple_golden_2/r0_101.jpg\n",
      "Validation/apple_golden_3/r0_1.jpg\n",
      "Validation/apple_golden_3/r0_1.jpg\n",
      "Validation/apple_golden_3/r0_101.jpg\n",
      "Validation/apple_golden_3/r0_101.jpg\n",
      "Validation/apple_granny_smith_1/r0_1.jpg\n",
      "Validation/apple_granny_smith_1/r0_1.jpg\n",
      "Validation/apple_granny_smith_1/r0_101.jpg\n",
      "Validation/apple_granny_smith_1/r0_101.jpg\n",
      "Validation/apple_hit_1/r0_1.jpg\n",
      "Validation/apple_hit_1/r0_1.jpg\n",
      "Validation/apple_hit_1/r0_101.jpg\n",
      "Validation/apple_hit_1/r0_101.jpg\n",
      "Validation/apple_pink_lady_1/r0_1.jpg\n",
      "Validation/apple_pink_lady_1/r0_1.jpg\n",
      "Validation/apple_pink_lady_1/r0_101.jpg\n",
      "Validation/apple_pink_lady_1/r0_101.jpg\n",
      "Validation/apple_red_1/r0_1.jpg\n",
      "Validation/apple_red_1/r0_1.jpg\n",
      "Validation/apple_red_1/r0_101.jpg\n",
      "Validation/apple_red_1/r0_101.jpg\n",
      "Validation/apple_red_2/r0_1.jpg\n",
      "Validation/apple_red_2/r0_1.jpg\n",
      "Validation/apple_red_2/r0_101.jpg\n",
      "Validation/apple_red_2/r0_101.jpg\n",
      "Validation/apple_red_3/r0_1.jpg\n",
      "Validation/apple_red_3/r0_1.jpg\n",
      "Validation/apple_red_3/r0_101.jpg\n",
      "Validation/apple_red_3/r0_101.jpg\n",
      "Validation/apple_red_delicios_1/r0_1.jpg\n",
      "Validation/apple_red_delicios_1/r0_1.jpg\n",
      "Validation/apple_red_delicios_1/r0_101.jpg\n",
      "Validation/apple_red_delicios_1/r0_101.jpg\n",
      "Validation/apple_red_yellow_1/r0_1.jpg\n",
      "Validation/apple_red_yellow_1/r0_1.jpg\n",
      "Validation/apple_red_yellow_1/r0_101.jpg\n",
      "Validation/apple_red_yellow_1/r0_101.jpg\n",
      "Validation/apple_rotten_1/r0_1.jpg\n",
      "Validation/apple_rotten_1/r0_1.jpg\n",
      "Validation/apple_rotten_1/r0_101.jpg\n",
      "Validation/apple_rotten_1/r0_101.jpg\n",
      "Validation/cabbage_white_1/r0_1.jpg\n",
      "Validation/cabbage_white_1/r0_1.jpg\n",
      "Validation/cabbage_white_1/r0_101.jpg\n",
      "Validation/cabbage_white_1/r0_101.jpg\n",
      "Validation/carrot_1/r0_1.jpg\n",
      "Validation/carrot_1/r0_1.jpg\n",
      "Validation/carrot_1/r0_101.jpg\n",
      "Validation/carrot_1/r0_101.jpg\n",
      "Validation/cucumber_1/r0_1.jpg\n",
      "Validation/cucumber_1/r0_1.jpg\n",
      "Validation/cucumber_1/r0_101.jpg\n",
      "Validation/cucumber_1/r0_101.jpg\n",
      "Validation/cucumber_3/r0_1.jpg\n",
      "Validation/cucumber_3/r0_1.jpg\n",
      "Validation/cucumber_3/r0_101.jpg\n",
      "Validation/cucumber_3/r0_101.jpg\n",
      "Validation/eggplant_violet_1/r0_1.jpg\n",
      "Validation/eggplant_violet_1/r0_1.jpg\n",
      "Validation/eggplant_violet_1/r0_101.jpg\n",
      "Validation/eggplant_violet_1/r0_101.jpg\n",
      "Validation/pear_1/r0_1.jpg\n",
      "Validation/pear_1/r0_1.jpg\n",
      "Validation/pear_1/r0_101.jpg\n",
      "Validation/pear_1/r0_101.jpg\n",
      "Validation/pear_3/r0_1.jpg\n",
      "Validation/pear_3/r0_1.jpg\n",
      "Validation/pear_3/r0_101.jpg\n",
      "Validation/pear_3/r0_101.jpg\n",
      "Validation/zucchini_1/r0_1.jpg\n",
      "Validation/zucchini_1/r0_1.jpg\n",
      "Validation/zucchini_1/r0_101.jpg\n",
      "Validation/zucchini_1/r0_101.jpg\n",
      "Validation/zucchini_dark_1/r0_1.jpg\n",
      "Validation/zucchini_dark_1/r0_1.jpg\n",
      "Validation/zucchini_dark_1/r0_101.jpg\n",
      "Validation/zucchini_dark_1/r0_101.jpg\n",
      "aws-programmatic-access-test-object\n"
     ]
    }
   ],
   "source": [
    "# Create SIFT descriptor\n",
    "sift = cv2.SIFT_create()\n",
    "    \n",
    "# Loop on .jpg pictures in AWS S3 Bucket\n",
    "for obj in s3_bucket.objects.all():      # Ne prendre que les .jpg !!!!\n",
    "    \n",
    "    key = obj.key\n",
    "    \n",
    "    print(key) \n",
    "    \n",
    "    if key.endswith('jpg'):        \n",
    "        print(key)\n",
    "        \n",
    "        # Read picture from AWS S3 Bucket\n",
    "        pict = np.array(Image.open(s3_bucket.Object(key).get()['Body']))\n",
    "\n",
    "        # Compute key points and picture descriptors (descript: numpy array with one line by interest point, 128 columns)\n",
    "        keypoints, descript = sift.detectAndCompute(pict, None)\n",
    "        \n",
    "        pd.DataFrame(descript)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Instantiate SparkSession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark create RDD example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o34.load.\n: java.lang.UnsupportedOperationException\r\n\tat org.apache.hadoop.fs.http.AbstractHttpFileSystem.listStatus(AbstractHttpFileSystem.java:94)\r\n\tat org.apache.hadoop.fs.http.HttpsFileSystem.listStatus(HttpsFileSystem.java:23)\r\n\tat org.apache.spark.util.HadoopFSUtils$.listLeafFiles(HadoopFSUtils.scala:225)\r\n\tat org.apache.spark.util.HadoopFSUtils$.$anonfun$parallelListLeafFilesInternal$1(HadoopFSUtils.scala:95)\r\n\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat scala.collection.TraversableLike.map(TraversableLike.scala:286)\r\n\tat scala.collection.TraversableLike.map$(TraversableLike.scala:279)\r\n\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\r\n\tat org.apache.spark.util.HadoopFSUtils$.parallelListLeafFilesInternal(HadoopFSUtils.scala:85)\r\n\tat org.apache.spark.util.HadoopFSUtils$.parallelListLeafFiles(HadoopFSUtils.scala:69)\r\n\tat org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.bulkListLeafFiles(InMemoryFileIndex.scala:158)\r\n\tat org.apache.spark.sql.execution.datasources.InMemoryFileIndex.listLeafFiles(InMemoryFileIndex.scala:131)\r\n\tat org.apache.spark.sql.execution.datasources.InMemoryFileIndex.refresh0(InMemoryFileIndex.scala:94)\r\n\tat org.apache.spark.sql.execution.datasources.InMemoryFileIndex.<init>(InMemoryFileIndex.scala:66)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource.createInMemoryFileIndex(DataSource.scala:565)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:409)\r\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:274)\r\n\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$3(DataFrameReader.scala:245)\r\n\tat scala.Option.getOrElse(Option.scala:189)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:245)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:188)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\r\n\tat java.lang.reflect.Method.invoke(Unknown Source)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.lang.Thread.run(Unknown Source)\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\BNPLEA~1\\AppData\\Local\\Temp/ipykernel_3784/3740888953.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0ms3_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"https://moncompartimentamoi.s3.eu-west-3.amazonaws.com/Test/apple_6/r0_103.jpg\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"image\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms3_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pyspark\\sql\\readwriter.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(self, path, format, schema, **options)\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1321\u001b[1;33m         return_value = get_return_value(\n\u001b[0m\u001b[0;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0;32m   1323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\py4j\\protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m                 raise Py4JJavaError(\n\u001b[0m\u001b[0;32m    327\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o34.load.\n: java.lang.UnsupportedOperationException\r\n\tat org.apache.hadoop.fs.http.AbstractHttpFileSystem.listStatus(AbstractHttpFileSystem.java:94)\r\n\tat org.apache.hadoop.fs.http.HttpsFileSystem.listStatus(HttpsFileSystem.java:23)\r\n\tat org.apache.spark.util.HadoopFSUtils$.listLeafFiles(HadoopFSUtils.scala:225)\r\n\tat org.apache.spark.util.HadoopFSUtils$.$anonfun$parallelListLeafFilesInternal$1(HadoopFSUtils.scala:95)\r\n\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat scala.collection.TraversableLike.map(TraversableLike.scala:286)\r\n\tat scala.collection.TraversableLike.map$(TraversableLike.scala:279)\r\n\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\r\n\tat org.apache.spark.util.HadoopFSUtils$.parallelListLeafFilesInternal(HadoopFSUtils.scala:85)\r\n\tat org.apache.spark.util.HadoopFSUtils$.parallelListLeafFiles(HadoopFSUtils.scala:69)\r\n\tat org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.bulkListLeafFiles(InMemoryFileIndex.scala:158)\r\n\tat org.apache.spark.sql.execution.datasources.InMemoryFileIndex.listLeafFiles(InMemoryFileIndex.scala:131)\r\n\tat org.apache.spark.sql.execution.datasources.InMemoryFileIndex.refresh0(InMemoryFileIndex.scala:94)\r\n\tat org.apache.spark.sql.execution.datasources.InMemoryFileIndex.<init>(InMemoryFileIndex.scala:66)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource.createInMemoryFileIndex(DataSource.scala:565)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:409)\r\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:274)\r\n\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$3(DataFrameReader.scala:245)\r\n\tat scala.Option.getOrElse(Option.scala:189)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:245)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:188)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\r\n\tat java.lang.reflect.Method.invoke(Unknown Source)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.lang.Thread.run(Unknown Source)\r\n"
     ]
    }
   ],
   "source": [
    "#s3_url = \"s3a://moncompartimentamoi/Test/apple_6/*\"\n",
    "s3_url = \"https://moncompartimentamoi.s3.eu-west-3.amazonaws.com/Test/apple_6/r0_103.jpg\"\n",
    "\n",
    "df = spark.read.format(\"image\").load(s3_url)\n",
    "\n",
    "print((df.count(), len(df.columns)))\n",
    "print(df.printSchema())\n",
    "\n",
    "df.select('image.nChannels', \"image.width\", \"image.height\", \"image.data\").show(truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_ImageSchema' object has no attribute 'readImages'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\BNPLEA~1\\AppData\\Local\\Temp/ipykernel_3784/3806685490.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImageSchema\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImageSchema\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadImages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms3_bucket\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m#\"Training/apple_6/\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: '_ImageSchema' object has no attribute 'readImages'"
     ]
    }
   ],
   "source": [
    "# Create PySpark RDD (Resilient Distributed Dataset)  from .jpg file\n",
    "from pyspark.ml.image import ImageSchema\n",
    "\n",
    "test = ImageSchema.readImages(s3_bucket) \n",
    "#\"Training/apple_6/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "image argument should be pyspark.sql.types.Row; however, it got [<class 'str'>].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\BNPLEA~1\\AppData\\Local\\Temp/ipykernel_3784/1222846742.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mload_picture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Training/apple_6/\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\BNPLEA~1\\AppData\\Local\\Temp/ipykernel_3784/1222846742.py\u001b[0m in \u001b[0;36mload_picture\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload_picture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImageSchema\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoNDArray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# argument de type pyspark.sql.types.Row\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;31m#test = ImageSchema.readImages(path) # AttributeError: '_ImageSchema' object has no attribute 'readImages'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pyspark\\ml\\image.py\u001b[0m in \u001b[0;36mtoNDArray\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m             raise TypeError(\n\u001b[0m\u001b[0;32m    163\u001b[0m                 \u001b[1;34m\"image argument should be pyspark.sql.types.Row; however, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m                 \"it got [%s].\" % type(image))\n",
      "\u001b[1;31mTypeError\u001b[0m: image argument should be pyspark.sql.types.Row; however, it got [<class 'str'>]."
     ]
    }
   ],
   "source": [
    "def load_picture(path):\n",
    "    test = ImageSchema.toNDArray(path)   # TypeError: image argument should be pyspark.sql.types.Row; however, it got [<class 'str'>].\n",
    "    #test = ImageSchema.readImages(path) # AttributeError: '_ImageSchema' object has no attribute 'readImages'\n",
    "    return test\n",
    "\n",
    "print(load_picture(\"Training/apple_6/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = spark.read.format('com.databricks.spark.csv').\\\n",
    "#            options(header='true', inferschema='true').\\\n",
    "#            load(\"/home/feng/Spark/Code/data/Advertising.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyspark.sql import Row\n",
    "\n",
    "#def load_dataframe(path):\n",
    "#    rdd = sc.textFile(path)\\\n",
    "#        .map(lambda line: line.split())\\\n",
    "#        .map(lambda words: Row(label=words[0], words=words[1:]))\n",
    "#    return spark.createDataFrame(rdd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clusters' descriptors <a class=\"anchor\" id=\"sub3_2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save starting time\n",
    "time_start = time.time()\n",
    "\n",
    "# Create KMeans clustering model\n",
    "kmeans = cluster.KMeans(n_clusters=KMEANS_N_CLUSTERS, random_state=42) \n",
    "\n",
    "# Train and predict using KMeans clustering model\n",
    "df_kpdesc_training = pd.concat([df_kpdesc_training, \\\n",
    "    pd.DataFrame(kmeans.fit_predict(df_kpdesc_training[df_kpdesc_training.columns[1:]].values), \\\n",
    "                 columns=['Desc_cluster'])], axis=1)\n",
    "\n",
    "# Compute time elapse\n",
    "elapse_s = time.time()-time_start\n",
    "elapse_m = int(elapse_s / 60)\n",
    "print('KMeans {} clusters done! Time elapsed: {} seconds ({} minutes)'.format(KMEANS_N_CLUSTERS, elapse_s, elapse_m))\n",
    "\n",
    "# Number of iterations run et Coordinates of cluster centers\n",
    "print(\"Case {} clusters: Converge after {} iterations\"\\\n",
    "      .format(kmeans.cluster_centers_.shape[0], kmeans.n_iter_)) \n",
    "\n",
    "print()\n",
    "print(\"Descriptor dataframe shape : \", df_kpdesc_training.shape)\n",
    "\n",
    "df_kpdesc_training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute frequency histogram on clusters' descriptors <a class=\"anchor\" id=\"sub3_3\"></a>\n",
    "samples: pictures x features: clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histo_freq(df_kpdesc_training):\n",
    "    \n",
    "    # Use index to count\n",
    "    df_kpdesc_training.reset_index(drop=False, inplace=True)\n",
    "    df_kpdesc_training = df_kpdesc_training.pivot_table('index', index='FullFileName', columns='Desc_cluster', \\\n",
    "                                                        aggfunc='count', fill_value=0, margins=True)\n",
    "    # Normalise: total for a picture is one\n",
    "    for c in df_kpdesc_training.columns[:-1]:\n",
    "        df_kpdesc_training[c] = df_kpdesc_training[c] / df_kpdesc_training['All']\n",
    "\n",
    "    # Drop unusefull information\n",
    "    df_kpdesc_training.drop(index='All', inplace=True)\n",
    "    df_kpdesc_training.drop(columns='All', inplace=True)\n",
    "    return df_kpdesc_training\n",
    "    \n",
    "df_kpdesc_training = histo_freq(df_kpdesc_training)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce dimension with PCA <a class=\"anchor\" id=\"sub3_4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_N_COMPONENTS = 0.90\n",
    "\n",
    "# Create PCA \n",
    "pca = decomposition.PCA()\n",
    "\n",
    "# Fit PCA\n",
    "pca.fit(df_kpdesc_training.values)\n",
    "\n",
    "# Draw explained variance absolute and cumulated\n",
    "df_eboulis = MyMod.graph_eboulis_valeurspropres(pca, (18, 18), True)\n",
    "\n",
    "print(\"{} clusters explain {}% of the variance\"\\\n",
    "           .format(df_eboulis[df_eboulis['explained_variance_ratio_cum'] > PCA_N_COMPONENTS]['rang'].min(), \\\n",
    "                   PCA_N_COMPONENTS * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PCA \n",
    "pca = decomposition.PCA(n_components=PCA_N_COMPONENTS)\n",
    "\n",
    "# Fit Transform PCA\n",
    "pict_features = pca.fit_transform(df_kpdesc_training.values)\n",
    "\n",
    "print()\n",
    "print(\"Matrix dimensions (pictures, visual words) : {}\".format(pict_features.shape)) \n",
    "\n",
    "# Get PC coordinates in cluster space\n",
    "df_contrib_PC = pd.DataFrame(pca.components_, columns=df_kpdesc_training.columns) \n",
    "df_contrib_PC.shape \n",
    "\n",
    "# Get the cluster best represented for each PC\n",
    "#df_contrib_PC_t = df_contrib_PC.transpose()\n",
    "lst_contrib = []\n",
    "for i in range(pca.n_components_):     \n",
    "    lst_contrib.append(df_contrib_PC.transpose()[i].idxmax(axis=0))\n",
    "    \n",
    "# Keep only the cluster best represented\n",
    "df_kpdesc_training = df_kpdesc_training[lst_contrib]\n",
    "del lst_contrib\n",
    "\n",
    "# Unduplicate identical columns\n",
    "df_kpdesc_training = df_kpdesc_training.T.groupby(level=0).first().T\n",
    "\n",
    "df_kpdesc_training.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laurence: sortie de la rÃ©duction de dimension (une matrice Ã©crite sur un fichier CSV ou autre)???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling <a class=\"anchor\" id=\"chapter4\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a KNN model <a class=\"anchor\" id=\"sub4_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create KNN model\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Train KNN model\n",
    "X_train = df_kpdesc_training.values\n",
    "y_train = df_main_training['Target_encoded'].values\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check learning curve <a class=\"anchor\" id=\"sub4_2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes_abs, train_scores, test_scores = learning_curve(knn, X_train, y_train, \n",
    "                                            cv=5, scoring='neg_median_absolute_error',\n",
    "                                            train_sizes=np.linspace(0.1, 1, 5), \n",
    "                                            random_state=42)\n",
    "plot = plt.figure(figsize=(12, 8))\n",
    "plot = plt.plot(train_sizes_abs, train_scores.mean(axis=1), label='train score')\n",
    "plot = plt.plot(train_sizes_abs, test_scores.mean(axis=1), label='validation score')\n",
    "plot = plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict and compare prediction to reality on Test dataset <a class=\"anchor\" id=\"sub4_3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def predict_class(df, kmeans_model, pca_col_lst, knn_model):\n",
    "    \n",
    "    # Save starting time\n",
    "    time_start = time.time()\n",
    "\n",
    "    # Extract descriptors\n",
    "    df_kpdesc = desc_extraction(df)\n",
    "\n",
    "    # Predict clusters' descriptors with KMEANS\n",
    "    df_kpdesc = pd.concat([df_kpdesc, \\\n",
    "        pd.DataFrame(kmeans.predict(df_kpdesc[df_kpdesc.columns[1:]].values), columns=['Desc_cluster'])], axis=1)\n",
    "\n",
    "    # Compute histogram for main clusters\n",
    "    df_kpdesc = histo_freq(df_kpdesc)    \n",
    "    df_kpdesc = df_kpdesc[pca_col_lst]\n",
    "\n",
    "    # Predict class with trained KNN\n",
    "    df = pd.concat([df, pd.DataFrame(knn.predict(df_kpdesc.values), columns=['Predict'])], axis=1)\n",
    "\n",
    "    # Compute time elapse\n",
    "    elapse_s = time.time()-time_start\n",
    "    elapse_m = int(elapse_s / 60)\n",
    "    print('Test predictions done! Time elapsed: {} seconds ({} minutes)'.format(elapse_s, elapse_m))\n",
    "    \n",
    "    # Assess result ARI\n",
    "    ari = metrics.adjusted_rand_score(df['Target_encoded'].values, df['Predict'].values)\n",
    "    print('Test predictions done! Adjusted Rand Index: {}'.format(ari))\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Select Test dataset\n",
    "df_main_test = df_main[df_main['Dataset'] == 'Test']\n",
    "df_main_test = dataset_reduction(df_main_test, TEST_SAMPLE_SIZE)\n",
    "\n",
    "# Predict on Test dataset\n",
    "df_main_test = predict_class(df_main_test, kmeans, df_kpdesc_training.columns, knn)\n",
    "df_main_test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict and compare prediction to reality on Validation dataset <a class=\"anchor\" id=\"sub4_4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Validation dataset\n",
    "df_main_validation = df_main[df_main['Dataset'] == 'Validation']\n",
    "df_main_validation = dataset_reduction(df_main_validation, VALIDATION_SAMPLE_SIZE)\n",
    "\n",
    "# Predict on Validation dataset\n",
    "df_main_validation = predict_class(df_main_validation, kmeans, df_kpdesc_training.columns, knn)\n",
    "df_main_validation.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a7e9a1149953069853d4d83ec46f22084dce8711",
    "collapsed": true
   },
   "source": [
    "* [Go to Table des matiÃ¨res](#chapter0)\n",
    "\n",
    "# End <a class=\"anchor\" id=\"chapter100\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''df_main: FullFileName, Dataset, Target, Picture, FileSize (in KB), Rotation, Index, Target_encoded\n",
    "df_meta: Target, Flag, Value, Target_encoded\n",
    "df_target_mapping: Target_encoded, Target\n",
    "\n",
    "df_main_training, df_main_test, df_main_validation: \n",
    "        FullFileName, Dataset, Target, Picture, FileSize (in KB), Rotation, Index, Target_encoded, Predict\n",
    "df_kpdesc_training: FullFileName, Desc_cluster'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_target_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_meta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
