{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective\n",
    "Set-up a first big data architecture using AWS products (Mobile application with a fruit pictures classifier engine)\n",
    "\n",
    "# Data\n",
    "Link to upload data: https://www.kaggle.com/moltean/fruits\n",
    "\n",
    "# Table of contents <a class=\"anchor\" id=\"chapter0\"></a> \n",
    "* [Imports and declarations](#chapter1)\n",
    "    * [Import packages](#sub1_1)\n",
    "    * [Declare constants](#sub1_2)\n",
    "* [Exploration of the full dataset](#chapter2)\n",
    "    * [Get picture information from local full dataset](#sub2_1)\n",
    "    * [Explore picture information](#sub2_2)\n",
    "    * [Get class information](#sub2_3) \n",
    "    * [Target label encoding](#sub2_4)\n",
    "* [Preparation of the local sampled picture set](#chapter3)\n",
    "    * [Create a local sampled picture set](#sub3_1)\n",
    "    * [Get picture information from local sampled picture set](#sub3_2)\n",
    "* [Transfer learning](#chapter4)\n",
    "* [To the stars](#chapter5)\n",
    "* [Old code](#chapter6)\n",
    "    * [Cluster's descriptors](#sub3_2)\n",
    "    * [Compute frequency histogram on clusters' descriptors](#sub3_3)\n",
    "    * [Reduce dimension with PCA](#sub3_4)\n",
    "* [Modelling](#chapter4)\n",
    "    * [Train a KNN model](#sub4_1)\n",
    "    * [Check learning curve](#sub4_2)\n",
    "    * [Predict and compare prediction to reality on Test dataset](#sub4_3)\n",
    "    * [Predict and compare prediction to reality on Validation dataset](#sub4_4)\n",
    "* [Go to End](#chapter100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and declarations <a class=\"anchor\" id=\"chapter1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d632b08c-d252-4238-b496-e2c6edebec4b",
    "_uuid": "eb13bf76d4e1e60d0703856ec391cdc2c5bdf1fb"
   },
   "source": [
    "## Import packages <a class=\"anchor\" id=\"sub1_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import P8_02_module as MyMod\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "import os\n",
    "from os import path\n",
    "import glob\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "\n",
    "from cv2 import cv2\n",
    "import PIL\n",
    "from PIL import Image, ImageDraw, ImageOps, ImageFilter\n",
    "\n",
    "from sklearn import cluster\n",
    "from sklearn import decomposition\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import findspark\n",
    "from pyspark import SparkContext\n",
    "\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare constants <a class=\"anchor\" id=\"sub1_2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample limitations\n",
    "GET_PICTURES_NB_PER_CLASS = 2\n",
    "\n",
    "# KMeans hyper-param\n",
    "KMEANS_N_CLUSTERS = 90\n",
    "\n",
    "# Local repositories\n",
    "LOCAL_SRC_PATH = '../fruits-360-original-size/'\n",
    "LOCAL_DEST_PATH = '../fruits-360-sample/'\n",
    "\n",
    "IMAGE_RESIZE = 224\n",
    "\n",
    "# S3 Bucket\n",
    "BUCKET_NAME = \"moncompartimentamoi\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration of the full dataset <a class=\"anchor\" id=\"chapter2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get picture information from local full dataset <a class=\"anchor\" id=\"sub2_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rep_2_picture_info(path):\n",
    "\n",
    "    # Initiate Dataframe with Dataset names, Target class names and Picture names\n",
    "    df = pd.DataFrame(columns = ['FullFileName', 'Dataset', 'Target', 'Picture', 'FileSize (in KB)']) \n",
    "\n",
    "    for file in glob.iglob(path+'**/*.jpg', recursive = True):\n",
    "\n",
    "        lst = file.split('\\\\')\n",
    "\n",
    "        # update DataFrame\n",
    "        lst.append(os.path.getsize(file) / 1024)  # in KBytes    \n",
    "        lst[0] = lst[0] + \"/\" + lst[1] + \"/\" + lst[2] + \"/\" + lst[3]\n",
    "        df.loc[len(df)] = lst\n",
    "\n",
    "    return df\n",
    "\n",
    "df_main = rep_2_picture_info(LOCAL_SRC_PATH)\n",
    "df_main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore picture information <a class=\"anchor\" id=\"sub2_2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess volumes and modalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " > 12 455 pictures, 24 target classes, 3 datasets  \n",
    " > 958 picture names mean that some pictures have the same name and are not classified in the same repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count pictures by target class and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(df_main.groupby(['Target', 'Dataset'])['Picture'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count pictures by target class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(df_main.groupby(['Target'])['Picture'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count dataset modality by picture name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset_mod = pd.DataFrame(df_main.groupby(['Picture'])['Dataset'].nunique())\n",
    "df_dataset_mod.rename(columns={'Dataset':'Dataset_mod'}, inplace=True)\n",
    "len(df_dataset_mod[df_dataset_mod['Dataset_mod'] > 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> No file with the same name in the different datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count target class modality by picture name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_target_mod = pd.DataFrame(df_main.groupby(['Picture'])['Target'].nunique())\n",
    "df_target_mod.rename(columns={'Target':'Target_mod'}, inplace=True)\n",
    "df_target_mod[df_target_mod['Target_mod'] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target_mod = df_target_mod.reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(df_target_mod.groupby(['Target_mod'])['Picture'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " > many files with the same name in the different target classes   \n",
    " > for instance, 156 files have the same name and appear in 24 different target class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_main[df_main['Picture'] == 'r0_0.jpg'][['Picture', 'Target', 'Dataset']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pict = Image.open(df_main['FullFileName'].iloc[20])\n",
    "plt.imshow(pict)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pict = Image.open(df_main['FullFileName'].iloc[40])\n",
    "plt.imshow(pict)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " > File name format: r?_image_index.jpg (e.g. r0_31.jpg or r1_12.jpg)  \n",
    " > \"r?\" stands for rotation axis (first one is r0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distinguish rotation axis and index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Laurence: supprimler les FutureWarning\n",
    "df_main[\"Rotation\"], df_main[\"Index\"] = df_main[\"Picture\"].str.split(\"_\", 1).str\n",
    "df_main[\"Rotation\"] = df_main[\"Rotation\"].str.replace('r','')\n",
    "df_main[\"Index\"] = df_main[\"Index\"].str.replace('.jpg','')\n",
    "df_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(df_main[\"Rotation\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pict = Image.open(df_main['FullFileName'].iloc[df_main[df_main['Rotation'] == '0'].head(1).index[0]])\n",
    "plt.imshow(pict)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pict = Image.open(df_main['FullFileName'].iloc[df_main[df_main['Rotation'] == '1'].head(1).index[0]])\n",
    "plt.imshow(pict)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pict = Image.open(df_main['FullFileName'].iloc[df_main[df_main['Rotation'] == '2'].head(1).index[0]])\n",
    "plt.imshow(pict)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " > 0 - queue top or down > rotation around the z-axis  \n",
    " > 1 - queue behind or ahead > rotation around the x-axis  \n",
    " > 2 - queue left or right > rotation around the y-axis  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target class count distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribution(df_in, dataset):\n",
    "    \n",
    "    df = df_in.copy()\n",
    "    \n",
    "    if dataset in ['Training', 'Test', 'Validation']:\n",
    "        df.drop(df[df['Dataset'] != dataset].index, inplace=True)\n",
    "    elif dataset != '*':\n",
    "        print(\"dataset argument should be 'Training', 'Test', 'Validation' or '*'\")\n",
    "        return -1\n",
    "        \n",
    "    df_distrib = pd.DataFrame(df.groupby(['Target'])['Picture'].count())\n",
    "    df_distrib.reset_index(drop=False, inplace=True)\n",
    "    df_distrib.rename(columns={'Picture':'Picture count', 'Target':'Class'}, inplace=True)\n",
    "    df_distrib = df_distrib.sort_values(by='Class', ascending=False)    \n",
    "\n",
    "    if len(df_distrib) == 0: return -1\n",
    "    \n",
    "    df_distrib.plot.barh(x='Class', y='Picture count', figsize=(12, 10))    \n",
    "    \n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ret = distribution(df_main, 'Training')\n",
    "ret = distribution(df_main, 'Test')\n",
    "ret = distribution(df_main, 'Validation')\n",
    "ret = distribution(df_main, '*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target class filesize average distribution  \n",
    "Logitech C920 camera and dedicated algorithm which extract the fruit from the background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(df_main.groupby('Target')['FileSize (in KB)'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df_main.groupby('Dataset')['FileSize (in KB)'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main['FileSize (in KB)'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get class information <a class=\"anchor\" id=\"sub2_3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = '../fruits-360-original-size/Meta/'\n",
    "\n",
    "df_class_add = pd.DataFrame(columns = ['PathName', 'Target', 'TxtName'])\n",
    "df_meta = pd.DataFrame(columns = ['Flag', 'Value'])\n",
    "\n",
    "for file in glob.iglob(path+'**/info.txt', recursive = True):\n",
    "    \n",
    "    df_meta_add = pd.read_csv(file, sep=\"=\", names=['Flag', 'Value'])\n",
    "        \n",
    "    df_class_add.loc[0] = file.split('\\\\')   \n",
    "        \n",
    "    df_meta = pd.concat([df_class_add.join(df_meta_add, how='cross'), df_meta])\n",
    "\n",
    "del df_class_add, df_meta_add\n",
    "\n",
    "df_meta.drop(columns=['PathName', 'TxtName'], inplace=True)\n",
    "df_meta = df_meta.sort_values(['Target', 'Flag'], ascending=True)\n",
    "df_meta.reset_index(drop=True, inplace=True)\n",
    "df_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta['Flag'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(df_meta['Flag'].unique(), columns=['Flag']).sort_values(by='Flag')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target label encoding  <a class=\"anchor\" id=\"sub2_4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_main, df_target_mapping = MyMod.encode_LabelEncoder(df_main, 'Target')\n",
    "df_main.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta, df_target_mapping = MyMod.encode_LabelEncoder(df_meta, 'Target')\n",
    "df_meta.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_target_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation of the local sampled picture set <a class=\"anchor\" id=\"chapter3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a local sampled picture set <a class=\"anchor\" id=\"sub3_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target_prec = \"\"\n",
    "for file in glob.iglob(LOCAL_SRC_PATH+'**/*.jpg', recursive = True):\n",
    "    \n",
    "    lst = file.split('\\\\')\n",
    "    \n",
    "    # Limit number of pictures per class(GET_PICTURES_NB_PER_CLASS)\n",
    "    if lst[2] == target_prec: \n",
    "        i += 1\n",
    "    else:\n",
    "        i = 0\n",
    "    target_prec = lst[2]\n",
    "    \n",
    "    if (lst[1] == 'Training' and i < 2*GET_PICTURES_NB_PER_CLASS) or \\\n",
    "                    (lst[1] != 'Training' and i < GET_PICTURES_NB_PER_CLASS):     \n",
    "                \n",
    "        # create the destination repository if necessary\n",
    "        if not os.path.exists(LOCAL_DEST_PATH+lst[1]+\"/\"+lst[2]):\n",
    "             os.makedirs(LOCAL_DEST_PATH+lst[1]+\"/\"+lst[2])\n",
    "\n",
    "        # copy the file to the destination repository\n",
    "        shutil.copyfile(LOCAL_SRC_PATH+lst[1]+\"/\"+lst[2]+\"/\"+lst[3], LOCAL_DEST_PATH+lst[1]+\"/\"+lst[2]+\"/\"+lst[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get picture information from local sampled picture set <a class=\"anchor\" id=\"sub3_2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_main = rep_2_picture_info(LOCAL_DEST_PATH)\n",
    "df_main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning <a class=\"anchor\" id=\"chapter4\"></a> \n",
    "because my dataset has too little data to train a full-scale model from scratch  \n",
    "\n",
    "Layers trainable attributes:\n",
    "- weights : list of all weights variables of the layer  \n",
    "- trainable_weights : list of those that are meant to be updated (via gradient descent) to minimize the loss during training  \n",
    "- non_trainable_weights : list of those that aren't meant to be trained (updated by the model during the forward pass)  \n",
    "- trainable : false moves all the layer's weights from trainable to non-trainable (\"freezing\" the layer)  \n",
    "The only built-in layer that has non-trainable weights is the BatchNormalization layer  \n",
    "\n",
    "Workflow 1 :  \n",
    "1 - Instantiate a base model and load pre-trained weights into it  \n",
    "2 - Freeze all layers in the base model by setting trainable = False  \n",
    "3 - Create a new model on top of the output of one/several layers from the base model  \n",
    "4 - Train your new model on your new dataset  (top layers to learn to turn the old features into predictions on a new dataset)   \n",
    "\n",
    "Workflow 2 : feature extraction  \n",
    "1 - Instantiate a base model and load pre-trained weights into it  \n",
    "2 - Run your new dataset through it and record the output of one/several layers from the base model   \n",
    "3 - Use that output as input data for a new, smaller model   \n",
    "advantage: you only run the base model once on your data, rather than once per epoch of training > a lot faster & cheaper  \n",
    "issue: doesn't allow you to dynamically modify the input data of your new model during training, which is required when doing data augmentation  \n",
    "\n",
    "Fine-tuning (optionnal): \n",
    "unfreeze the entire/partial model you obtained and re-training it on the new data with a very low learning rate  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "#from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "#from tensorflow.keras.preprocessing import image\n",
    "#from tensorflow.keras.utils import image_dataset_from_directory\n",
    "\n",
    "#import keras\n",
    "##from tensorflow.keras import layers,Dense,Flatten\n",
    "##from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "#from tensorflow.keras.losses import BinaryCrossentropy\n",
    "#from tensorflow.keras.metrics import BinaryAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "RESNET50_POOLING_AVERAGE = 'avg'\n",
    "DENSE_LAYER_ACTIVATION = 'softmax'\n",
    "OBJECTIVE_FUNCTION = 'categorical_crossentropy'\n",
    "LOSS_METRICS = ['accuracy']\n",
    "\n",
    "# EARLY_STOP_PATIENCE must be < NUM_EPOCHS\n",
    "NUM_EPOCHS = 10\n",
    "EARLY_STOP_PATIENCE = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a base model: ResNet50 with pre-trained weights\n",
    "#\"Residual Network\" with 50 layers. Convolutional Neural Network\n",
    "\n",
    "pretrained_model = ResNet50(\n",
    "    # Weights pre-trained on ImageNet: resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5 \n",
    "    # in cache directory (~/.keras/models)\n",
    "    weights='imagenet',                                 \n",
    "    input_shape=(IMAGE_RESIZE, IMAGE_RESIZE, 3),\n",
    "    # Do not include the ImageNet fully-connected layer at the top of the network\n",
    "    include_top=False,\n",
    "    classes=24)\n",
    "# input_tensor=None, pooling=[None, 'avg'], classifier_activation=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all layers in the base model by setting trainable = False\n",
    "pretrained_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new model on top of the output of one layer from the base model\n",
    "inputs = keras.Input(shape=(IMAGE_RESIZE, IMAGE_RESIZE, 3))\n",
    "\n",
    "# Makes base_model run in inference mode by passing training to False (necessary for fine-tuning)\n",
    "x = pretrained_model(inputs, training=False)\n",
    "\n",
    "# Convert features of shape 'base_model.output_shape[1:]' to vectors\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "# A Dense classifier with 65 units et activation 'softmax'\n",
    "outputs = keras.layers.Dense(65, activation=DENSE_LAYER_ACTIVATION)(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on new data\n",
    "sgd = optimizers.SGD(lr = 0.01, decay = 1e-6, momentum = 0.9, nesterov = True)\n",
    "model.compile(optimizer=sgd, loss=OBJECTIVE_FUNCTION, metrics=LOSS_METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 96 images belonging to 24 classes.\n",
      "Found 48 images belonging to 24 classes.\n",
      "<class 'keras.preprocessing.image.DirectoryIterator'>\n"
     ]
    }
   ],
   "source": [
    "# Read Training data\n",
    "train_datagen = ImageDataGenerator(\n",
    "                    rescale=1. / 255,\n",
    "                    shear_range=0.2,\n",
    "                    zoom_range=0.2,\n",
    "                    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                    LOCAL_DEST_PATH+'Training/',\n",
    "                    target_size=(IMAGE_RESIZE, IMAGE_RESIZE),\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "                    LOCAL_DEST_PATH+'Validation/',\n",
    "                    target_size=(IMAGE_RESIZE, IMAGE_RESIZE),\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    class_mode='categorical')\n",
    "\n",
    "print(type(train_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'categorical_crossentropy/softmax_cross_entropy_with_logits' defined at (most recent call last):\n    File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n      await self.process_one()\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n      await dispatch(*args)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n      await result\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n      reply_content = await reply_content\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_cell\n      result = self._run_cell(\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2947, in _run_cell\n      return runner(coro)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3172, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3364, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3444, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\BNPLEA~1\\AppData\\Local\\Temp/ipykernel_12332/984358097.py\", line 4, in <module>\n      model.fit(train_generator, epochs=NUM_EPOCHS,\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 918, in compute_loss\n      return self.compiled_loss(\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\losses.py\", line 245, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\losses.py\", line 1789, in categorical_crossentropy\n      return backend.categorical_crossentropy(\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend.py\", line 5098, in categorical_crossentropy\n      return tf.nn.softmax_cross_entropy_with_logits(\nNode: 'categorical_crossentropy/softmax_cross_entropy_with_logits'\nlogits and labels must be broadcastable: logits_size=[16,65] labels_size=[16,24]\n\t [[{{node categorical_crossentropy/softmax_cross_entropy_with_logits}}]] [Op:__inference_train_function_9674]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\BNPLEA~1\\AppData\\Local\\Temp/ipykernel_12332/3706744077.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcb_checkpointer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'best.hdf5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonitor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_best_only\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'auto'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m model.fit(train_generator, epochs=NUM_EPOCHS, \n\u001b[0m\u001b[0;32m      5\u001b[0m           \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcb_checkpointer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcb_early_stopper\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m           validation_data=validation_generator) \n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'categorical_crossentropy/softmax_cross_entropy_with_logits' defined at (most recent call last):\n    File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n      await self.process_one()\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n      await dispatch(*args)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n      await result\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n      reply_content = await reply_content\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_cell\n      result = self._run_cell(\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2947, in _run_cell\n      return runner(coro)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3172, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3364, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3444, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\BNPLEA~1\\AppData\\Local\\Temp/ipykernel_12332/984358097.py\", line 4, in <module>\n      model.fit(train_generator, epochs=NUM_EPOCHS,\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 918, in compute_loss\n      return self.compiled_loss(\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\losses.py\", line 245, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\losses.py\", line 1789, in categorical_crossentropy\n      return backend.categorical_crossentropy(\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend.py\", line 5098, in categorical_crossentropy\n      return tf.nn.softmax_cross_entropy_with_logits(\nNode: 'categorical_crossentropy/softmax_cross_entropy_with_logits'\nlogits and labels must be broadcastable: logits_size=[16,65] labels_size=[16,24]\n\t [[{{node categorical_crossentropy/softmax_cross_entropy_with_logits}}]] [Op:__inference_train_function_9674]"
     ]
    }
   ],
   "source": [
    "cb_early_stopper = EarlyStopping(monitor = 'loss', patience = EARLY_STOP_PATIENCE)\n",
    "cb_checkpointer = ModelCheckpoint(filepath = 'best.hdf5', monitor = 'loss', save_best_only = True, mode = 'auto')\n",
    "\n",
    "model.fit(train_generator, \n",
    "          epochs=NUM_EPOCHS, \n",
    "          callbacks=[cb_checkpointer, cb_early_stopper],\n",
    "          validation_data=validation_generator) \n",
    "\n",
    "#Detected at node 'categorical_crossentropy/softmax_cross_entropy_with_logits' defined at (most recent call last):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To the stars <a class=\"anchor\" id=\"chapter5\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "#from pyspark.sql import Row\n",
    "from pyspark.ml.image import ImageSchema\n",
    "from pyspark.ml.linalg import DenseVector, VectorUDT\n",
    "\n",
    "# Path to hadoop \n",
    "findspark.init(\"C:\\spark\\spark-3.2.1-bin-hadoop3.2\")\n",
    "\n",
    "# Instantiate SparkSession\n",
    "spark = SparkSession \\\n",
    "            .builder \\\n",
    "            .appName(\"Python Spark Keypoints to RDD\") \\\n",
    "            .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "            .getOrCreate()\n",
    "#spark.createDataFrame(rdd)\n",
    "\n",
    "# Instantiate a SparkContext\n",
    "sc = SparkContext()\n",
    "# Verify Spark version\n",
    "print(\"Spark version:{}\".format(sc.version))\n",
    "\n",
    "# Instantiate S3 client\n",
    "s3_client = boto3.client('s3', region_name='eu-west-3')\n",
    "# Instantiate S3 resource\n",
    "#s3_resource = boto3.resource('s3')\n",
    "# Instantiate S3 bucket\n",
    "#s3_bucket = s3_resource.Bucket(BUCKET_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though SparkContext used to be an entry point prior to 2.0, it is not completely replaced with SparkSession.\n",
    "Many features of SparkContext are still available and used in Spark 2.0 and later.  \n",
    "You should also know that SparkSession internally creates SparkConfig and SparkContext with the configuration provided with SparkSession."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read pictures 1\n",
    "#df = spark.read.format(\"image\").load(LOCAL_DEST_PATH) \n",
    "#df.show()\n",
    "\n",
    "# Read pictures 2 (ImageSchema.imageFields)\n",
    "#img2vec = F.udf(lambda x: DenseVector(ImageSchema.toNDArray(x).flatten()), VectorUDT())\n",
    "#df = df.withColumn('vecs', img2vec(\"image\"))\n",
    "#df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer pictures from LOCAL_DEST_PATH local repository to S3 bucket\n",
    "for file in glob.iglob(LOCAL_DEST_PATH+'**/*.jpg', recursive = True):\n",
    "    \n",
    "    lst = file.split('\\\\')\n",
    "        \n",
    "    # upload the image in the S3 bucket  \n",
    "    s3_client.upload_file(lst[0], BUCKET_NAME, lst[1]+\"/\"+lst[2]+\"/\"+lst[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old code <a class=\"anchor\" id=\"chapter6\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extration des descripteurs : jpg sur S3 > descripteurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_image_from_s3(key):\n",
    "    \"\"\"Load image file from s3.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    key : string           Path in s3\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np array               Image array\n",
    "    \"\"\"   \n",
    "    #object = s3_bucket.Object(key)\n",
    "    #response = object.get()\n",
    "    #file_stream = response['Body']    \n",
    "    #im = Image.open(file_stream)\n",
    "    \n",
    "    return np.array(Image.open(s3_bucket.Object(key).get()['Body']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create SIFT descriptor\n",
    "sift = cv2.SIFT_create()\n",
    "    \n",
    "# Loop on .jpg pictures in AWS S3 Bucket\n",
    "for obj in s3_bucket.objects.all():      # Ne prendre que les .jpg !!!!\n",
    "    \n",
    "    key = obj.key\n",
    "    \n",
    "    print(key) \n",
    "    \n",
    "    if key.endswith('jpg'):        \n",
    "        print(key)\n",
    "        \n",
    "        # Read picture from AWS S3 Bucket\n",
    "        pict = np.array(Image.open(s3_bucket.Object(key).get()['Body']))\n",
    "\n",
    "        # Compute key points and picture descriptors (descript: numpy array with one line by interest point, 128 columns)\n",
    "        keypoints, descript = sift.detectAndCompute(pict, None)\n",
    "        \n",
    "        pd.DataFrame(descript)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#s3_url = \"s3a://moncompartimentamoi/Test/apple_6/*\"\n",
    "s3_url = \"https://moncompartimentamoi.s3.eu-west-3.amazonaws.com/Test/apple_6/r0_103.jpg\"\n",
    "\n",
    "df = spark.read.format(\"image\").load(s3_url)\n",
    "\n",
    "print((df.count(), len(df.columns)))\n",
    "print(df.printSchema())\n",
    "\n",
    "df.select('image.nChannels', \"image.width\", \"image.height\", \"image.data\").show(truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PySpark RDD (Resilient Distributed Dataset)  from .jpg file\n",
    "from pyspark.ml.image import ImageSchema\n",
    "\n",
    "test = ImageSchema.readImages(s3_bucket) \n",
    "#\"Training/apple_6/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_picture(path):\n",
    "    test = ImageSchema.toNDArray(path)   \n",
    "    # TypeError: image argument should be pyspark.sql.types.Row; however, it got [<class 'str'>].\n",
    "    \n",
    "    #test = ImageSchema.readImages(path) \n",
    "    # AttributeError: '_ImageSchema' object has no attribute 'readImages'\n",
    "    \n",
    "    return test\n",
    "\n",
    "print(load_picture(\"Training/apple_6/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clusters' descriptors <a class=\"anchor\" id=\"sub3_2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save starting time\n",
    "time_start = time.time()\n",
    "\n",
    "# Create KMeans clustering model\n",
    "kmeans = cluster.KMeans(n_clusters=KMEANS_N_CLUSTERS, random_state=42) \n",
    "\n",
    "# Train and predict using KMeans clustering model\n",
    "df_kpdesc_training = pd.concat([df_kpdesc_training, \\\n",
    "    pd.DataFrame(kmeans.fit_predict(df_kpdesc_training[df_kpdesc_training.columns[1:]].values), \\\n",
    "                 columns=['Desc_cluster'])], axis=1)\n",
    "\n",
    "# Compute time elapse\n",
    "elapse_s = time.time()-time_start\n",
    "elapse_m = int(elapse_s / 60)\n",
    "print('KMeans {} clusters done! Time elapsed: {} seconds ({} minutes)'.format(KMEANS_N_CLUSTERS, elapse_s, elapse_m))\n",
    "\n",
    "# Number of iterations run et Coordinates of cluster centers\n",
    "print(\"Case {} clusters: Converge after {} iterations\"\\\n",
    "      .format(kmeans.cluster_centers_.shape[0], kmeans.n_iter_)) \n",
    "\n",
    "print()\n",
    "print(\"Descriptor dataframe shape : \", df_kpdesc_training.shape)\n",
    "\n",
    "df_kpdesc_training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute frequency histogram on clusters' descriptors <a class=\"anchor\" id=\"sub3_3\"></a>\n",
    "samples: pictures x features: clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histo_freq(df_kpdesc_training):\n",
    "    \n",
    "    # Use index to count\n",
    "    df_kpdesc_training.reset_index(drop=False, inplace=True)\n",
    "    df_kpdesc_training = df_kpdesc_training.pivot_table('index', index='FullFileName', columns='Desc_cluster', \\\n",
    "                                                        aggfunc='count', fill_value=0, margins=True)\n",
    "    # Normalise: total for a picture is one\n",
    "    for c in df_kpdesc_training.columns[:-1]:\n",
    "        df_kpdesc_training[c] = df_kpdesc_training[c] / df_kpdesc_training['All']\n",
    "\n",
    "    # Drop unusefull information\n",
    "    df_kpdesc_training.drop(index='All', inplace=True)\n",
    "    df_kpdesc_training.drop(columns='All', inplace=True)\n",
    "    return df_kpdesc_training\n",
    "    \n",
    "df_kpdesc_training = histo_freq(df_kpdesc_training)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce dimension with PCA <a class=\"anchor\" id=\"sub3_4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_N_COMPONENTS = 0.90\n",
    "\n",
    "# Create PCA \n",
    "pca = decomposition.PCA()\n",
    "\n",
    "# Fit PCA\n",
    "pca.fit(df_kpdesc_training.values)\n",
    "\n",
    "# Draw explained variance absolute and cumulated\n",
    "df_eboulis = MyMod.graph_eboulis_valeurspropres(pca, (18, 18), True)\n",
    "\n",
    "print(\"{} clusters explain {}% of the variance\"\\\n",
    "           .format(df_eboulis[df_eboulis['explained_variance_ratio_cum'] > PCA_N_COMPONENTS]['rang'].min(), \\\n",
    "                   PCA_N_COMPONENTS * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PCA \n",
    "pca = decomposition.PCA(n_components=PCA_N_COMPONENTS)\n",
    "\n",
    "# Fit Transform PCA\n",
    "pict_features = pca.fit_transform(df_kpdesc_training.values)\n",
    "\n",
    "print()\n",
    "print(\"Matrix dimensions (pictures, visual words) : {}\".format(pict_features.shape)) \n",
    "\n",
    "# Get PC coordinates in cluster space\n",
    "df_contrib_PC = pd.DataFrame(pca.components_, columns=df_kpdesc_training.columns) \n",
    "df_contrib_PC.shape \n",
    "\n",
    "# Get the cluster best represented for each PC\n",
    "#df_contrib_PC_t = df_contrib_PC.transpose()\n",
    "lst_contrib = []\n",
    "for i in range(pca.n_components_):     \n",
    "    lst_contrib.append(df_contrib_PC.transpose()[i].idxmax(axis=0))\n",
    "    \n",
    "# Keep only the cluster best represented\n",
    "df_kpdesc_training = df_kpdesc_training[lst_contrib]\n",
    "del lst_contrib\n",
    "\n",
    "# Unduplicate identical columns\n",
    "df_kpdesc_training = df_kpdesc_training.T.groupby(level=0).first().T\n",
    "\n",
    "df_kpdesc_training.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling <a class=\"anchor\" id=\"chapter4\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a KNN model <a class=\"anchor\" id=\"sub4_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create KNN model\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Train KNN model\n",
    "X_train = df_kpdesc_training.values\n",
    "y_train = df_main_training['Target_encoded'].values\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check learning curve <a class=\"anchor\" id=\"sub4_2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes_abs, train_scores, test_scores = learning_curve(knn, X_train, y_train, \n",
    "                                            cv=5, scoring='neg_median_absolute_error',\n",
    "                                            train_sizes=np.linspace(0.1, 1, 5), \n",
    "                                            random_state=42)\n",
    "plot = plt.figure(figsize=(12, 8))\n",
    "plot = plt.plot(train_sizes_abs, train_scores.mean(axis=1), label='train score')\n",
    "plot = plt.plot(train_sizes_abs, test_scores.mean(axis=1), label='validation score')\n",
    "plot = plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict and compare prediction to reality on Test dataset <a class=\"anchor\" id=\"sub4_3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def predict_class(df, kmeans_model, pca_col_lst, knn_model):\n",
    "    \n",
    "    # Save starting time\n",
    "    time_start = time.time()\n",
    "\n",
    "    # Extract descriptors\n",
    "    df_kpdesc = desc_extraction(df)\n",
    "\n",
    "    # Predict clusters' descriptors with KMEANS\n",
    "    df_kpdesc = pd.concat([df_kpdesc, \\\n",
    "        pd.DataFrame(kmeans.predict(df_kpdesc[df_kpdesc.columns[1:]].values), columns=['Desc_cluster'])], axis=1)\n",
    "\n",
    "    # Compute histogram for main clusters\n",
    "    df_kpdesc = histo_freq(df_kpdesc)    \n",
    "    df_kpdesc = df_kpdesc[pca_col_lst]\n",
    "\n",
    "    # Predict class with trained KNN\n",
    "    df = pd.concat([df, pd.DataFrame(knn.predict(df_kpdesc.values), columns=['Predict'])], axis=1)\n",
    "\n",
    "    # Compute time elapse\n",
    "    elapse_s = time.time()-time_start\n",
    "    elapse_m = int(elapse_s / 60)\n",
    "    print('Test predictions done! Time elapsed: {} seconds ({} minutes)'.format(elapse_s, elapse_m))\n",
    "    \n",
    "    # Assess result ARI\n",
    "    ari = metrics.adjusted_rand_score(df['Target_encoded'].values, df['Predict'].values)\n",
    "    print('Test predictions done! Adjusted Rand Index: {}'.format(ari))\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Select Test dataset\n",
    "df_main_test = df_main[df_main['Dataset'] == 'Test']\n",
    "\n",
    "# Predict on Test dataset\n",
    "df_main_test = predict_class(df_main_test, kmeans, df_kpdesc_training.columns, knn)\n",
    "df_main_test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict and compare prediction to reality on Validation dataset <a class=\"anchor\" id=\"sub4_4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Validation dataset\n",
    "df_main_validation = df_main[df_main['Dataset'] == 'Validation']\n",
    "\n",
    "# Predict on Validation dataset\n",
    "df_main_validation = predict_class(df_main_validation, kmeans, df_kpdesc_training.columns, knn)\n",
    "df_main_validation.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a7e9a1149953069853d4d83ec46f22084dce8711",
    "collapsed": true
   },
   "source": [
    "* [Go to Table des matières](#chapter0)\n",
    "\n",
    "# End <a class=\"anchor\" id=\"chapter100\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''df_main: FullFileName, Dataset, Target, Picture, FileSize (in KB), Rotation, Index, Target_encoded\n",
    "df_meta: Target, Flag, Value, Target_encoded\n",
    "df_target_mapping: Target_encoded, Target\n",
    "\n",
    "df_main_training, df_main_test, df_main_validation: \n",
    "        FullFileName, Dataset, Target, Picture, FileSize (in KB), Rotation, Index, Target_encoded, Predict\n",
    "df_kpdesc_training: FullFileName, Desc_cluster'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
