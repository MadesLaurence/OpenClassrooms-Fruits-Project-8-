{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MadesLaurence/OpenClassrooms-Fruits-Project-8-/blob/main/P8_05_notebook_cloud.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaEl_gVii_C9"
      },
      "source": [
        "# Objective\n",
        "Set-up a first big data architecture using AWS products (Mobile application with a fruit pictures classifier engine)\n",
        "\n",
        "# Data\n",
        "Link to upload data: https://www.kaggle.com/moltean/fruits\n",
        "\n",
        "# Table of contents <a class=\"anchor\" id=\"chapter0\"></a> \n",
        "* [Imports and declarations](#chapter1)\n",
        "    * [Import packages](#sub1_1)\n",
        "    * [Declare constants](#sub1_2)\n",
        "* [Load data](#chapter5)\n",
        "    * [Load pictures](#sub5_1)\n",
        "    * [Distinguish Target and Dataset](#sub5_2)\n",
        "    * [Index Target](#sub5_3)\n",
        "* [Instantiate a ResNet50 model with pre-trained weights](#chapter6)\n",
        "* [Features extraction](#chapter7)\n",
        "    * [Functions](#sub7_1)\n",
        "    * [Features extraction](#sub7_2)\n",
        "    * [Features reduction](#sub7_3)\n",
        "* [Train a new model using pre-computed features](#chapter8)\n",
        "    * [Prepare my new model](#sub8_1)\n",
        "    * [Train my new model on Training dataset](#sub8_2)\n",
        "    * [Predict fruit class with my new model on Test dataset](#sub8_3)\n",
        "* [Visualise classification results](#chapter9)\n",
        "* [Go to End](#chapter100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22adXcvNi_DB"
      },
      "source": [
        "# Imports and declarations <a class=\"anchor\" id=\"chapter1\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "d632b08c-d252-4238-b496-e2c6edebec4b",
        "_uuid": "eb13bf76d4e1e60d0703856ec391cdc2c5bdf1fb",
        "id": "dZVWZRWsi_DC"
      },
      "source": [
        "## Import packages <a class=\"anchor\" id=\"sub1_1\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "jdnNImv8i_DC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9711452e-e6e7-4493-8d7a-5f97fea81e83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PySpark version:3.2.1\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from typing import Iterator\n",
        "import os\n",
        "from os import path\n",
        "import glob\n",
        "import shutil\n",
        "import time\n",
        "import io\n",
        "\n",
        "import PIL\n",
        "from PIL import Image\n",
        "\n",
        "# Pyspark\n",
        "import pyspark\n",
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession, Row\n",
        "from pyspark.sql.types import IntegerType, ArrayType, FloatType\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.functions import element_at, split\n",
        "from pyspark.sql.functions import col, pandas_udf, PandasUDFType\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "from pyspark.ml.feature import PCA\n",
        "from pyspark.ml.linalg import Vectors, VectorUDT\n",
        "print(\"PySpark version:{}\".format(pyspark.__version__)) # Verify PySpark version\n",
        "\n",
        "# Tensorflow, Keras\n",
        "import tensorflow as tf\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gt0HycIci_DE"
      },
      "source": [
        "## Declare constants <a class=\"anchor\" id=\"sub1_2\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GvNoVfhMi_DF"
      },
      "outputs": [],
      "source": [
        "# Image size\n",
        "IMAGE_RESIZE = 224\n",
        "\n",
        "# Locations\n",
        "SOURCE = 's3://moncompartimentamoi/pictures/*'\n",
        "OUTPUT = 's3://moncompartimentamoi/results'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ghpp_J6ai_DR"
      },
      "source": [
        "# Load data <a class=\"anchor\" id=\"chapter5\"></a> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-89zGFui_DR"
      },
      "source": [
        "## Load pictures <a class=\"anchor\" id=\"sub5_1\"></a> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1DPqWEGi_DT"
      },
      "source": [
        "### Get pictures in a Spark DataFrame in \"binaryFile\" format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVP47Zx1i_DT"
      },
      "outputs": [],
      "source": [
        "pictures_df = spark.read.format(\"binaryFile\") \\\n",
        "            .option(\"pathGlobFilter\", \"*.jpg\") \\\n",
        "            .option(\"recursiveFileLookup\", \"true\") \\\n",
        "            .load(DATASOURCE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gltVO-uUi_DT",
        "outputId": "b9aa64c6-67fb-45df-8091-b9239f19db72"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "193"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# Count sample size\n",
        "pictures_df.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnxa9dFhi_DT",
        "outputId": "a29bb1ff-ba62-4735-d58f-2542d61bac05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-------------------+------+--------------------+\n",
            "|                path|   modificationTime|length|             content|\n",
            "+--------------------+-------------------+------+--------------------+\n",
            "|file:/content/dri...|2022-03-21 14:12:59|123514|[FF D8 FF E0 00 1...|\n",
            "|file:/content/dri...|2022-03-21 14:13:00|122525|[FF D8 FF E0 00 1...|\n",
            "|file:/content/dri...|2022-03-21 14:12:59|121530|[FF D8 FF E0 00 1...|\n",
            "|file:/content/dri...|2022-03-21 14:13:00|119805|[FF D8 FF E0 00 1...|\n",
            "|file:/content/dri...|2022-03-21 14:13:00|119068|[FF D8 FF E0 00 1...|\n",
            "+--------------------+-------------------+------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Spark DataFrame visualisation\n",
        "pictures_df.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IOTpvuei_DT",
        "outputId": "2ff0e7b5-e45b-4170-faa6-35b8bc4e6434"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- path: string (nullable = true)\n",
            " |-- modificationTime: timestamp (nullable = true)\n",
            " |-- length: long (nullable = true)\n",
            " |-- content: binary (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Spark DataFrame scheme\n",
        "pictures_df.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cA7IYjKOi_DT"
      },
      "source": [
        "## Distinguish Target and DataSet <a class=\"anchor\" id=\"sub5_2\"></a> "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmkEagGDi_DU"
      },
      "outputs": [],
      "source": [
        "# Extract Target from path\n",
        "pictures_df = pictures_df.withColumn('target', element_at(split(pictures_df['path'], \"/\"), -2))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract DataSet from path\n",
        "pictures_df = pictures_df.withColumn('dataset', element_at(split(pictures_df['path'], \"/\"), -3))"
      ],
      "metadata": {
        "id": "53xVF3u1Vhn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Index Target <a class=\"anchor\" id=\"sub5_3\"></a> "
      ],
      "metadata": {
        "id": "h8RYVEFWiwaP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "indexer = StringIndexer(inputCol=\"target\", outputCol=\"target_code\") \n",
        "pictures_df = indexer.fit(pictures_df).transform(pictures_df)\n",
        "pictures_df.show(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOcVKyuxic2S",
        "outputId": "d714cdf5-13a4-47d2-eb76-74d468d5d299"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-------------------+------+--------------------+---------------+----------+-----------+\n",
            "|                path|   modificationTime|length|             content|         target|   dataset|target_code|\n",
            "+--------------------+-------------------+------+--------------------+---------------+----------+-----------+\n",
            "|file:/content/dri...|2022-03-21 14:12:59|123514|[FF D8 FF E0 00 1...|    apple_hit_1|      Test|        7.0|\n",
            "|file:/content/dri...|2022-03-21 14:13:00|122525|[FF D8 FF E0 00 1...|    apple_hit_1|  Training|        7.0|\n",
            "|file:/content/dri...|2022-03-21 14:12:59|121530|[FF D8 FF E0 00 1...|    apple_hit_1|      Test|        7.0|\n",
            "|file:/content/dri...|2022-03-21 14:13:00|119805|[FF D8 FF E0 00 1...|    apple_hit_1|Validation|        7.0|\n",
            "|file:/content/dri...|2022-03-21 14:13:00|119068|[FF D8 FF E0 00 1...|    apple_hit_1|  Training|        7.0|\n",
            "|file:/content/dri...|2022-03-21 14:13:01| 96730|[FF D8 FF E0 00 1...|cabbage_white_1|Validation|       15.0|\n",
            "|file:/content/dri...|2022-03-21 14:13:00| 96281|[FF D8 FF E0 00 1...|cabbage_white_1|  Training|       15.0|\n",
            "|file:/content/dri...|2022-03-21 14:13:00| 95790|[FF D8 FF E0 00 1...|cabbage_white_1|  Training|       15.0|\n",
            "|file:/content/dri...|2022-03-21 14:13:01| 95624|[FF D8 FF E0 00 1...|cabbage_white_1|Validation|       15.0|\n",
            "|file:/content/dri...|2022-03-21 14:13:00| 95486|[FF D8 FF E0 00 1...|cabbage_white_1|  Training|       15.0|\n",
            "|file:/content/dri...|2022-03-21 14:12:59| 95139|[FF D8 FF E0 00 1...|cabbage_white_1|      Test|       15.0|\n",
            "|file:/content/dri...|2022-03-21 14:13:00| 94969|[FF D8 FF E0 00 1...|cabbage_white_1|  Training|       15.0|\n",
            "|file:/content/dri...|2022-03-21 14:12:59| 94910|[FF D8 FF E0 00 1...|cabbage_white_1|      Test|       15.0|\n",
            "|file:/content/dri...|2022-03-21 14:13:00| 94753|[FF D8 FF E0 00 1...|    apple_hit_1|  Training|        7.0|\n",
            "|file:/content/dri...|2022-03-21 14:13:00| 89920|[FF D8 FF E0 00 1...|    apple_hit_1|Validation|        7.0|\n",
            "|file:/content/dri...|2022-03-21 14:13:00| 89253|[FF D8 FF E0 00 1...|    apple_hit_1|  Training|        7.0|\n",
            "|file:/content/dri...|2022-03-21 14:13:00| 77515|[FF D8 FF E0 00 1...|         pear_3|  Training|       21.0|\n",
            "|file:/content/dri...|2022-03-21 14:13:01| 76561|[FF D8 FF E0 00 1...|         pear_3|Validation|       21.0|\n",
            "|file:/content/dri...|2022-03-21 14:13:00| 74814|[FF D8 FF E0 00 1...|         pear_3|  Training|       21.0|\n",
            "|file:/content/dri...|2022-03-21 14:12:59| 74182|[FF D8 FF E0 00 1...|         pear_3|      Test|       21.0|\n",
            "+--------------------+-------------------+------+--------------------+---------------+----------+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pictures_df = pictures_df.withColumn(\"target_code\",pictures_df.target_code.cast(IntegerType()))\n",
        "pictures_df.show(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nj6Er0Gm3MVa",
        "outputId": "9f86dcd5-10a3-4fa6-f6d1-954ece5a4b9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-------------------+------+--------------------+---------------+----------+-----------+\n",
            "|                path|   modificationTime|length|             content|         target|   dataset|target_code|\n",
            "+--------------------+-------------------+------+--------------------+---------------+----------+-----------+\n",
            "|file:/content/dri...|2022-03-21 14:12:59|123514|[FF D8 FF E0 00 1...|    apple_hit_1|      Test|          7|\n",
            "|file:/content/dri...|2022-03-21 14:13:00|122525|[FF D8 FF E0 00 1...|    apple_hit_1|  Training|          7|\n",
            "|file:/content/dri...|2022-03-21 14:12:59|121530|[FF D8 FF E0 00 1...|    apple_hit_1|      Test|          7|\n",
            "|file:/content/dri...|2022-03-21 14:13:00|119805|[FF D8 FF E0 00 1...|    apple_hit_1|Validation|          7|\n",
            "|file:/content/dri...|2022-03-21 14:13:00|119068|[FF D8 FF E0 00 1...|    apple_hit_1|  Training|          7|\n",
            "|file:/content/dri...|2022-03-21 14:13:01| 96730|[FF D8 FF E0 00 1...|cabbage_white_1|Validation|         15|\n",
            "|file:/content/dri...|2022-03-21 14:13:00| 96281|[FF D8 FF E0 00 1...|cabbage_white_1|  Training|         15|\n",
            "|file:/content/dri...|2022-03-21 14:13:00| 95790|[FF D8 FF E0 00 1...|cabbage_white_1|  Training|         15|\n",
            "|file:/content/dri...|2022-03-21 14:13:01| 95624|[FF D8 FF E0 00 1...|cabbage_white_1|Validation|         15|\n",
            "|file:/content/dri...|2022-03-21 14:13:00| 95486|[FF D8 FF E0 00 1...|cabbage_white_1|  Training|         15|\n",
            "|file:/content/dri...|2022-03-21 14:12:59| 95139|[FF D8 FF E0 00 1...|cabbage_white_1|      Test|         15|\n",
            "|file:/content/dri...|2022-03-21 14:13:00| 94969|[FF D8 FF E0 00 1...|cabbage_white_1|  Training|         15|\n",
            "|file:/content/dri...|2022-03-21 14:12:59| 94910|[FF D8 FF E0 00 1...|cabbage_white_1|      Test|         15|\n",
            "|file:/content/dri...|2022-03-21 14:13:00| 94753|[FF D8 FF E0 00 1...|    apple_hit_1|  Training|          7|\n",
            "|file:/content/dri...|2022-03-21 14:13:00| 89920|[FF D8 FF E0 00 1...|    apple_hit_1|Validation|          7|\n",
            "|file:/content/dri...|2022-03-21 14:13:00| 89253|[FF D8 FF E0 00 1...|    apple_hit_1|  Training|          7|\n",
            "|file:/content/dri...|2022-03-21 14:13:00| 77515|[FF D8 FF E0 00 1...|         pear_3|  Training|         21|\n",
            "|file:/content/dri...|2022-03-21 14:13:01| 76561|[FF D8 FF E0 00 1...|         pear_3|Validation|         21|\n",
            "|file:/content/dri...|2022-03-21 14:13:00| 74814|[FF D8 FF E0 00 1...|         pear_3|  Training|         21|\n",
            "|file:/content/dri...|2022-03-21 14:12:59| 74182|[FF D8 FF E0 00 1...|         pear_3|      Test|         21|\n",
            "+--------------------+-------------------+------+--------------------+---------------+----------+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Y8c349Ai_DU",
        "outputId": "cb576e70-2924-473f-8777-5ba551f0a0fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- path: string (nullable = true)\n",
            " |-- modificationTime: timestamp (nullable = true)\n",
            " |-- length: long (nullable = true)\n",
            " |-- content: binary (nullable = true)\n",
            " |-- target: string (nullable = true)\n",
            " |-- dataset: string (nullable = true)\n",
            " |-- target_code: integer (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Spark DataFrame scheme\n",
        "pictures_df.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instantiate a ResNet50 model with pre-trained weights  <a class=\"anchor\" id=\"chapter6\"></a> \n",
        "\"Residual Network\" with 50 layers. Convolutional Neural Network"
      ],
      "metadata": {
        "id": "YLmjU2qkNU7a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cm-bZnApi_DV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36844c7b-ead4-433c-f9ad-1b848c33fdae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n",
            "94781440/94765736 [==============================] - 1s 0us/step\n",
            "175\n"
          ]
        }
      ],
      "source": [
        "pre_model = ResNet50(\n",
        "    # Weights pre-trained on ImageNet: resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5 \n",
        "    # in cache directory (~/.keras/models)\n",
        "    weights='imagenet',                                 \n",
        "    input_shape=(IMAGE_RESIZE, IMAGE_RESIZE, 3),\n",
        "    # Do not include the ImageNet fully-connected layer at the top of the network\n",
        "    include_top=False,\n",
        "    classes=24)\n",
        "print(len(pre_model.layers))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pre_model.summary()"
      ],
      "metadata": {
        "id": "N6oluSgiZWoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nnqYXl9Gi_DV"
      },
      "outputs": [],
      "source": [
        "# Broadcast the model weights in the SparkContext\n",
        "bc_model_weights = sc.broadcast(pre_model.get_weights())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rF8OT-7i_DU"
      },
      "source": [
        "# Features extraction <a class=\"anchor\" id=\"chapter7\"></a> \n",
        "\n",
        "1 - Instantiate a base model and load pre-trained weights into it  \n",
        "2 - Run your new dataset through it and record the output of one/several layers from the base model   \n",
        "3 - Use that output as input data for a new, smaller model   \n",
        "advantage: you only run the base model once on your data, rather than once per epoch of training > a lot faster & cheaper  \n",
        "issue: doesn't allow you to dynamically modify the input data of your new model during training, which is required when doing data augmentation  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_M5EdOCi_DV"
      },
      "source": [
        "## Functions  <a class=\"anchor\" id=\"sub7_1\"></a> \n",
        "https://docs.databricks.com/_static/notebooks/deep-learning/deep-learning-transfer-learning-keras.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JENsMZpmi_DV"
      },
      "outputs": [],
      "source": [
        "def model_fn():\n",
        "    \"\"\"\n",
        "    Returns a ResNet50 model with top layer removed and broadcasted pretrained weights.\n",
        "    \"\"\"\n",
        "    \n",
        "    model = ResNet50(\n",
        "        weights=None,                                 \n",
        "        input_shape=(IMAGE_RESIZE, IMAGE_RESIZE, 3),\n",
        "        include_top=False,         # Do not include the ImageNet fully-connected layer at the top of the network\n",
        "        classes=24)\n",
        "\n",
        "    # set model weights to previously broadcasted weights\n",
        "    model.set_weights(bc_model_weights.value)\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYn2o081i_DW"
      },
      "source": [
        "### Preprocess one image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ankztbrzi_DW"
      },
      "outputs": [],
      "source": [
        "def preprocess(content):\n",
        "    \"\"\"\n",
        "    Preprocesses raw image bytes for prediction.\n",
        "    \"\"\"\n",
        "    # Redimension of the picture\n",
        "    img = Image.open(io.BytesIO(content)).resize([IMAGE_RESIZE, IMAGE_RESIZE])\n",
        "    \n",
        "    # Converts the PIL Image instance to a Numpy array\n",
        "    arr = img_to_array(img)\n",
        "    \n",
        "    # Preprocesses a tensor or Numpy array encoding a batch of images\n",
        "    return preprocess_input(arr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zh4gGm3Ii_DW"
      },
      "source": [
        "### Featurize a pd.Series of images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UnL6TBphi_DW"
      },
      "outputs": [],
      "source": [
        "def featurize_series(model, content_series):\n",
        "    \"\"\"\n",
        "    Featurize a pd.Series of raw images using the input model.\n",
        "    :return: a pd.Series of image features\n",
        "    \"\"\"\n",
        "    # Join the sequence of arrays along the first axis. The stacked array has one more dimension than the input arrays\n",
        "    input = np.stack(content_series.map(preprocess))\n",
        "    \n",
        "    # Compute predictions \n",
        "    preds = model.predict(input)\n",
        "\n",
        "    # For some layers, output features will be multi-dimensional tensors.\n",
        "    # We flatten the feature tensors to vectors for easier storage in Spark DataFrames.\n",
        "    output = [p.flatten() for p in preds]\n",
        "    \n",
        "    return pd.Series(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRAscqv_i_DW"
      },
      "source": [
        "###  Featurize all images\n",
        "PandasUDFType.SCALAR_ITER used to amortize the cost of loading large models on workers  \n",
        "\n",
        "PandasUDF User Defined Function  \n",
        "New Pandas UDFs with Python type hints  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NA9-0WL-i_DX"
      },
      "outputs": [],
      "source": [
        "@pandas_udf('array<float>')\n",
        "def featurize_udf(content_series_iter: Iterator[pd.Series]) -> Iterator[pd.Series]:\n",
        "    '''\n",
        "    This method is a Scalar Iterator pandas UDF wrapping our featurization function.\n",
        "    The decorator specifies that this returns a Spark DataFrame column of type ArrayType(FloatType).\n",
        "\n",
        "    :param content_series_iter: This argument is an iterator over batches of data, where each batch\n",
        "                              is a pandas Series of image data.\n",
        "    '''\n",
        "    # With Scalar Iterator pandas UDFs, we can load the model once and then re-use it\n",
        "    # for multiple data batches. This amortizes the overhead of loading big models.    \n",
        "    pre_model = model_fn()\n",
        "    \n",
        "    for content_series in content_series_iter:\n",
        "        \n",
        "        # Yield returns a generator to the caller and the execution of the code starts only when the generator is iterated \n",
        "        yield featurize_series(pre_model, content_series)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwqPhrCHi_DX"
      },
      "source": [
        "## Features extraction  <a class=\"anchor\" id=\"sub7_2\"></a> "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pandas UDFs on large records (e.g., very large images) can run into Out Of Memory (OOM) errors.\n",
        "# If you hit such errors in the cell below, try reducing the Arrow batch size via `maxRecordsPerBatch`.\n",
        "spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"1024\")"
      ],
      "metadata": {
        "id": "1AKdEv00Wl_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYp5FuEGi_DX",
        "outputId": "6645e225-3036-4067-9ac9-3c52b61e65a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature extraction done! Time elapsed: 0.10957050323486328 seconds (0 minutes)\n"
          ]
        }
      ],
      "source": [
        "# Save starting time\n",
        "time_start = time.time()\n",
        "\n",
        "# Large model to the full dataset\n",
        "BATCH_SIZE = 16 # Dispatches dataframe over 16 partitions\n",
        "features_df = pictures_df.repartition(BATCH_SIZE).select(col(\"dataset\"), col('target'), col('target_code'), col(\"content\"), featurize_udf(\"content\").alias(\"X_features\"))\n",
        "\n",
        "# Compute time elapse\n",
        "elapse_s = time.time()-time_start\n",
        "elapse_m = int(elapse_s / 60)\n",
        "print('Feature extraction done! Time elapsed: {} seconds ({} minutes)'.format(elapse_s, elapse_m))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features_df.persist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "sGNIddLsmPK_",
        "outputId": "001b29fb-a48c-4eb5-c458-a809508c40d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "+--------+--------------------+-----------+--------------------+--------------------+\n",
              "| dataset|              target|target_code|             content|          X_features|\n",
              "+--------+--------------------+-----------+--------------------+--------------------+\n",
              "|    Test|              pear_3|         21|[FF D8 FF E0 00 1...|[0.0, 0.0, 0.0, 0...|\n",
              "|Training|          cucumber_3|         18|[FF D8 FF E0 00 1...|[2.2741177, 0.0, ...|\n",
              "|Training|         apple_red_3|         11|[FF D8 FF E0 00 1...|[0.0, 0.0, 0.0, 0...|\n",
              "|Training|apple_crimson_snow_1|          2|[FF D8 FF E0 00 1...|[0.0, 0.0, 0.0, 0...|\n",
              "|Training|apple_red_delicios_1|         12|[FF D8 FF E0 00 1...|[0.0, 0.0, 0.0, 0...|\n",
              "+--------+--------------------+-----------+--------------------+--------------------+\n",
              "only showing top 5 rows"
            ],
            "text/html": [
              "<table border='1'>\n",
              "<tr><th>dataset</th><th>target</th><th>target_code</th><th>content</th><th>X_features</th></tr>\n",
              "<tr><td>Test</td><td>pear_3</td><td>21</td><td>[FF D8 FF E0 00 1...</td><td>[0.0, 0.0, 0.0, 0...</td></tr>\n",
              "<tr><td>Training</td><td>cucumber_3</td><td>18</td><td>[FF D8 FF E0 00 1...</td><td>[2.2741177, 0.0, ...</td></tr>\n",
              "<tr><td>Training</td><td>apple_red_3</td><td>11</td><td>[FF D8 FF E0 00 1...</td><td>[0.0, 0.0, 0.0, 0...</td></tr>\n",
              "<tr><td>Training</td><td>apple_crimson_snow_1</td><td>2</td><td>[FF D8 FF E0 00 1...</td><td>[0.0, 0.0, 0.0, 0...</td></tr>\n",
              "<tr><td>Training</td><td>apple_red_delicios_1</td><td>12</td><td>[FF D8 FF E0 00 1...</td><td>[0.0, 0.0, 0.0, 0...</td></tr>\n",
              "</table>\n",
              "only showing top 5 rows\n"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MDXh21CK5MG",
        "outputId": "dd3d20a9-67ec-4748-b45c-73f9ffb4e247"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------------------+-----------+--------------------+--------------------+\n",
            "|   dataset|              target|target_code|             content|          X_features|\n",
            "+----------+--------------------+-----------+--------------------+--------------------+\n",
            "|      Test|              pear_3|         21|[FF D8 FF E0 00 1...|[0.0, 0.0, 0.0, 0...|\n",
            "|  Training|          cucumber_3|         18|[FF D8 FF E0 00 1...|[2.2741177, 0.0, ...|\n",
            "|  Training|         apple_red_3|         11|[FF D8 FF E0 00 1...|[0.0, 0.0, 0.0, 0...|\n",
            "|  Training|apple_crimson_snow_1|          2|[FF D8 FF E0 00 1...|[0.0, 0.0, 0.0, 0...|\n",
            "|  Training|apple_red_delicios_1|         12|[FF D8 FF E0 00 1...|[0.0, 0.0, 0.0, 0...|\n",
            "|  Training|         apple_red_2|         10|[FF D8 FF E0 00 1...|[0.0, 0.0, 0.0, 0...|\n",
            "|Validation|      apple_golden_1|          3|[FF D8 FF E0 00 1...|[0.0, 0.0, 0.0, 0...|\n",
            "|  Training|          zucchini_1|         22|[FF D8 FF E0 00 1...|[0.0, 0.0, 0.0, 0...|\n",
            "|  Training|      apple_golden_2|          4|[FF D8 FF E0 00 1...|[0.0, 0.0, 0.0, 0...|\n",
            "|      Test|      apple_golden_2|          4|[FF D8 FF E0 00 1...|[0.0, 0.0, 0.0, 0...|\n",
            "|Validation|   eggplant_violet_1|         19|[FF D8 FF E0 00 1...|[0.68835497, 0.0,...|\n",
            "|Validation|      apple_golden_1|          3|[FF D8 FF E0 00 1...|[0.0, 0.0, 0.0, 0...|\n",
            "|  Training|          cucumber_3|         18|[FF D8 FF E0 00 1...|[1.9688822, 0.0, ...|\n",
            "|  Training|         apple_red_3|         11|[FF D8 FF E0 00 1...|[0.0, 0.0, 0.0, 0...|\n",
            "|Validation|              pear_1|         20|[FF D8 FF E0 00 1...|[0.0, 0.0, 0.0, 0...|\n",
            "|  Training|          cucumber_3|         18|[FF D8 FF E0 00 1...|[0.0, 0.0, 0.0, 0...|\n",
            "|  Training|              pear_1|         20|[FF D8 FF E0 00 1...|[0.0, 0.0, 0.0, 0...|\n",
            "|Validation|          zucchini_1|         22|[FF D8 FF E0 00 1...|[0.0, 0.0, 0.0, 0...|\n",
            "|  Training|     zucchini_dark_1|         23|[FF D8 FF E0 00 1...|[0.0, 0.0, 0.0, 0...|\n",
            "|  Training|   apple_pink_lady_1|          8|[FF D8 FF E0 00 1...|[0.0, 0.0, 0.0, 0...|\n",
            "+----------+--------------------+-----------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "picture_cnt = features_df.count()\n",
        "avg_elapse_s = elapse_s / picture_cnt\n",
        "\n",
        "print('Number of pictures: {}'.format(picture_cnt))\n",
        "print('Average time elapsed per picture: {} seconds'.format(avg_elapse_s))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNLw7J-ZlRv1",
        "outputId": "2d254f4b-ba86-4a6b-de01-adc2dd02088f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of pictures: 193\n",
            "Average time elapsed per picture: 0.0005677228146884108 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Features reduction  <a class=\"anchor\" id=\"sub7_3\"></a> "
      ],
      "metadata": {
        "id": "7LVyCvPsExOZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pca_transformation(df, n_components=10):\n",
        "    \n",
        "    \"\"\"\n",
        "    Applique un algorithme de PCA sur l'ensemble des images pour réduire la dimension de chaque image \n",
        "    du jeu de données.\n",
        "    \n",
        "    Paramètres:\n",
        "    df(pyspark dataFrame): contient une colonne avec les données images\n",
        "    n_components(int): nombre de dimensions à conserver\n",
        "    \"\"\"\n",
        "    # Initilisation du temps de calcul\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Les données images sont converties au format vecteur dense\n",
        "    to_vector_udf = udf(lambda r: Vectors.dense(r), VectorUDT())\n",
        "    df = df.withColumn('X_vectors', to_vector_udf('X_features'))\n",
        "\n",
        "    # Entrainement de l'algorithme\n",
        "    pca = PCA(k=n_components, inputCol='X_vectors', outputCol='X_vectors_pca')\n",
        "    model_pca = pca.fit(df)\n",
        "\n",
        "    # Transformation des images sur les k premières composantes\n",
        "    df = model_pca.transform(df)\n",
        "    \n",
        "    # Affiche le temps de calcul\n",
        "    print(\"Temps d'execution {:.2f} secondes\".format(time.time() - start_time))\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biYedQUX841F",
        "outputId": "2ac77302-d841-4361-c683-8104f42ed613"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Temps d'execution 1816.13 secondes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_df = pca_transformation(features_df)"
      ],
      "metadata": {
        "id": "cZsvXY6W-PU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UKe6Niki_DX",
        "outputId": "2a2ba0fb-c413-4279-f55e-1cbdd82b5233"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------------------+-----------+--------------------+--------------------+--------------------+--------------------+\n",
            "|   dataset|              target|target_code|             content|          X_features|           X_vectors|       X_vectors_pca|\n",
            "+----------+--------------------+-----------+--------------------+--------------------+--------------------+--------------------+\n",
            "|      Test|              pear_3|         21|[FF D8 FF E0 00 1...|[0.0, 0.0, 0.0, 0...|[0.0,0.0,0.0,0.0,...|[-87.598921875144...|\n",
            "|  Training|          cucumber_3|         18|[FF D8 FF E0 00 1...|[2.2741177, 0.0, ...|[2.27411770820617...|[143.200677678075...|\n",
            "|  Training|         apple_red_3|         11|[FF D8 FF E0 00 1...|[0.0, 0.0, 0.0, 0...|[0.0,0.0,0.0,0.0,...|[-122.91375325607...|\n",
            "|  Training|apple_crimson_snow_1|          2|[FF D8 FF E0 00 1...|[0.0, 0.0, 0.0, 0...|[0.0,0.0,0.0,0.0,...|[-112.00103849373...|\n",
            "|  Training|apple_red_delicios_1|         12|[FF D8 FF E0 00 1...|[0.0, 0.0, 0.0, 0...|[0.0,0.0,0.0,0.0,...|[-59.714756389049...|\n",
            "|  Training|         apple_red_2|         10|[FF D8 FF E0 00 1...|[0.0, 0.0, 0.0, 0...|[0.0,0.0,0.0,0.0,...|[-126.11310758031...|\n",
            "|Validation|      apple_golden_1|          3|[FF D8 FF E0 00 1...|[0.0, 0.0, 0.0, 0...|[0.0,0.0,0.0,0.0,...|[-50.676643645096...|\n",
            "|  Training|          zucchini_1|         22|[FF D8 FF E0 00 1...|[0.0, 0.0, 0.0, 0...|[0.0,0.0,0.0,0.0,...|[194.058802273283...|\n",
            "|  Training|      apple_golden_2|          4|[FF D8 FF E0 00 1...|[0.0, 0.0, 0.0, 0...|[0.0,0.0,0.0,0.0,...|[-103.81263408462...|\n",
            "|      Test|      apple_golden_2|          4|[FF D8 FF E0 00 1...|[0.0, 0.0, 0.0, 0...|[0.0,0.0,0.0,0.0,...|[-105.59812836738...|\n",
            "|Validation|   eggplant_violet_1|         19|[FF D8 FF E0 00 1...|[0.68835497, 0.0,...|[0.68835496902465...|[213.012229623437...|\n",
            "|Validation|      apple_golden_1|          3|[FF D8 FF E0 00 1...|[0.0, 0.0, 0.0, 0...|[0.0,0.0,0.0,0.0,...|[-68.036564795038...|\n",
            "|  Training|          cucumber_3|         18|[FF D8 FF E0 00 1...|[1.9688822, 0.0, ...|[1.96888220310211...|[152.380494909531...|\n",
            "|  Training|         apple_red_3|         11|[FF D8 FF E0 00 1...|[0.0, 0.0, 0.0, 0...|[0.0,0.0,0.0,0.0,...|[-112.06719784331...|\n",
            "|Validation|              pear_1|         20|[FF D8 FF E0 00 1...|[0.0, 0.0, 0.0, 0...|[0.0,0.0,0.0,0.0,...|[-1.4441427987911...|\n",
            "|  Training|          cucumber_3|         18|[FF D8 FF E0 00 1...|[0.0, 0.0, 0.0, 0...|[0.0,0.0,0.0,0.0,...|[116.833323771591...|\n",
            "|  Training|              pear_1|         20|[FF D8 FF E0 00 1...|[0.0, 0.0, 0.0, 0...|[0.0,0.0,0.0,0.0,...|[-13.215704643634...|\n",
            "|Validation|          zucchini_1|         22|[FF D8 FF E0 00 1...|[0.0, 0.0, 0.0, 0...|[0.0,0.0,0.0,0.0,...|[169.182672144196...|\n",
            "|  Training|     zucchini_dark_1|         23|[FF D8 FF E0 00 1...|[0.0, 0.0, 0.0, 0...|[0.0,0.0,0.0,0.0,...|[217.355824690547...|\n",
            "|  Training|   apple_pink_lady_1|          8|[FF D8 FF E0 00 1...|[0.0, 0.0, 0.0, 0...|[0.0,0.0,0.0,0.0,...|[-111.22134379550...|\n",
            "+----------+--------------------+-----------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "final_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# write spark dataframe to a Parquet file\n",
        "final_df.write.mode(\"overwrite\").parquet(OUTPUT+\"/reduced_features_parquet\")"
      ],
      "metadata": {
        "id": "aDyf5ibapQrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgnwTt6ri_DX"
      },
      "source": [
        "# Train a new model using pre-computed features <a class=\"anchor\" id=\"chapter8\"></a> \n",
        "\n",
        "Layers trainable attributes:\n",
        "- weights : list of all weights variables of the layer  \n",
        "- trainable_weights : list of those that are meant to be updated (via gradient descent) to minimize the loss during training  \n",
        "- non_trainable_weights : list of those that aren't meant to be trained (updated by the model during the forward pass)  \n",
        "- trainable : false moves all the layer's weights from trainable to non-trainable (\"freezing\" the layer)  \n",
        "The only built-in layer that has non-trainable weights is the BatchNormalization layer  \n",
        "\n",
        "1 - Instantiate a base model and load pre-trained weights into it  \n",
        "2 - Freeze all layers in the base model by setting trainable = False  \n",
        "3 - Create a new model on top of the output of one/several layers from the base model  \n",
        "4 - Train your new model on your new dataset  (top layers to learn to turn the old features into predictions on a new dataset)   \n",
        "\n",
        "Fine-tuning (optionnal): \n",
        "unfreeze the entire/partial model you obtained and re-training it on the new data with a very low learning rate  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pj3oDzFXi_DY"
      },
      "source": [
        "## Prepare my new model <a class=\"anchor\" id=\"sub8_1\"></a> "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def add_layers_2_model(pretrained_model):\n",
        "    \"\"\"\n",
        "\n",
        "    \"\"\"    \n",
        "    # Freeze all layers in the base model by setting trainable = False\n",
        "    pretrained_model.trainable = False\n",
        "\n",
        "    # Create a new model on top of the output of one layer from the model ------------------------------------------- \n",
        "    new_model = Sequential()\n",
        "\n",
        "    new_model.add(pretrained_model)\n",
        "\n",
        "    new_model.add(Flatten())\n",
        "    new_model.add(Dense(512, activation='relu'))\n",
        "    new_model.add(Dense(25, activation='softmax'))\n",
        "\n",
        "    # Compile\n",
        "    sgd = optimizers.SGD(learning_rate = 0.01, decay = 1e-6, momentum = 0.9, nesterov = True)\n",
        "    OBJECTIVE_FUNCTION = 'categorical_crossentropy'\n",
        "    LOSS_METRICS = ['accuracy']\n",
        "    new_model.compile(optimizer=sgd, loss=OBJECTIVE_FUNCTION, metrics=LOSS_METRICS)\n",
        "    \n",
        "    return new_model"
      ],
      "metadata": {
        "id": "gh9d2-D3Cw3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_model = add_layers_2_model(pre_model)\n",
        "new_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrPpfpy1O2if",
        "outputId": "e9b2d204-c2ac-492b-ad12-d07fc8fe90a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 100352)            0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 512)               51380736  \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 25)                12825     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 74,981,273\n",
            "Trainable params: 51,393,561\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxp6uOmMi_DZ"
      },
      "source": [
        "Spark workers need to access the model and its weights.  \n",
        "For moderately sized models (< 1GB in size), a good practice is to download the model to the Spark driver and \n",
        "then broadcast the weights to the workers.  \n",
        "For large models (> 1GB), it is best to load the model weights from distributed storage to workers directly.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8ItnWVGi_DZ"
      },
      "source": [
        "## Train my new model on Training dataset <a class=\"anchor\" id=\"sub8_2\"></a> "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(content):\n",
        "    # Redimension of the picture\n",
        "    img = Image.open(io.BytesIO(content)).resize([IMAGE_RESIZE, IMAGE_RESIZE])\n",
        "    \n",
        "    # Converts the PIL Image instance to a Numpy array\n",
        "    arr = img_to_array(img)\n",
        "    \n",
        "    # Preprocesses a Numpy array encoding a batch of images\n",
        "    # The images are converted from RGB to BGR, then each color channel is zero-centered with respect to the ImageNet dataset, without scaling\n",
        "    # data_format=None > \"channels_last\" assumes the dimension order is (rows, cols, channels)\n",
        "    arr_temp = preprocess_input(arr, data_format=None)\n",
        "    \n",
        "    return arr_temp\n",
        "\n",
        "    # Return a copy of the array data as a (nested) Python list. Data items are converted to the nearest compatible builtin Python type, via the item function.\n",
        "    # Convert to a list whose values are Python primitives instead of numpy objects numpy.float32 (mismatched data types between Python and Spark)\n",
        "    #return arr_temp.tolist()\n",
        "\n",
        "    #return arr_temp.astype(np.float).tolist()\n",
        "    #return tf.convert_to_tensor(arr_temp, dtype=tf.float32)\n",
        "    #return tf.convert_to_tensor(arr_temp.astype(np.float).tolist())"
      ],
      "metadata": {
        "id": "5FOpjZf2db8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train with PySpark Functions (UDF): to be further developped  \n",
        "https://changhsinlee.com/pyspark-udf/"
      ],
      "metadata": {
        "id": "JiLzKEFLnu8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess_udf = udf(lambda content_series: preprocess(content_series), ArrayType(FloatType()))\n",
        "\n",
        "preprocess_df = pictures_df.select('dataset', 'target', 'target_code', preprocess_udf('content').alias(\"model_input\"))\n",
        "preprocess_df.show()"
      ],
      "metadata": {
        "id": "8b2UJTDMgeH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess_df.show(1, False, True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJBDfFqslRJ_",
        "outputId": "d74c8c8e-01bb-4812-b04c-a24b33804e02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-RECORD 0-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            " dataset     | Test                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
            " target      | apple_hit_1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
            " target_code | 7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
            " model_input | [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null] \n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img = Image.open(GOOGLE_DEST_PATH+'Training/apple_6/r0_0.jpg').resize([IMAGE_RESIZE, IMAGE_RESIZE])\n",
        "type(img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWCMT5bEdghS",
        "outputId": "50e4267a-af92-4cc8-db3a-ed941407b5fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PIL.Image.Image"
            ]
          },
          "metadata": {},
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arr = img_to_array(img)\n",
        "type(arr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UA-PCk6md_-j",
        "outputId": "5a5dd3f0-e6d7-4f70-948c-eb571a46094b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arr.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8-JsyM6eFHd",
        "outputId": "b7807696-c817-49a7-f1b8-bc2fa3e37649"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLWl-7SCeIYA",
        "outputId": "010348cf-458a-425f-a808-5219e8351cef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[255., 255., 255.],\n",
              "        [255., 255., 255.],\n",
              "        [255., 255., 255.],\n",
              "        ...,\n",
              "        [255., 255., 255.],\n",
              "        [255., 255., 255.],\n",
              "        [255., 255., 255.]],\n",
              "\n",
              "       [[255., 255., 255.],\n",
              "        [255., 255., 255.],\n",
              "        [255., 255., 255.],\n",
              "        ...,\n",
              "        [255., 255., 255.],\n",
              "        [255., 255., 255.],\n",
              "        [255., 255., 255.]],\n",
              "\n",
              "       [[255., 255., 255.],\n",
              "        [255., 255., 255.],\n",
              "        [255., 255., 255.],\n",
              "        ...,\n",
              "        [255., 255., 255.],\n",
              "        [255., 255., 255.],\n",
              "        [255., 255., 255.]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[255., 255., 255.],\n",
              "        [255., 255., 255.],\n",
              "        [255., 255., 255.],\n",
              "        ...,\n",
              "        [255., 255., 255.],\n",
              "        [255., 255., 255.],\n",
              "        [255., 255., 255.]],\n",
              "\n",
              "       [[255., 255., 255.],\n",
              "        [255., 255., 255.],\n",
              "        [255., 255., 255.],\n",
              "        ...,\n",
              "        [255., 255., 255.],\n",
              "        [255., 255., 255.],\n",
              "        [255., 255., 255.]],\n",
              "\n",
              "       [[255., 255., 255.],\n",
              "        [255., 255., 255.],\n",
              "        [255., 255., 255.],\n",
              "        ...,\n",
              "        [255., 255., 255.],\n",
              "        [255., 255., 255.],\n",
              "        [255., 255., 255.]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arr_temp = preprocess_input(arr, data_format=None)\n",
        "arr_temp.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frQDW0J_dXmw",
        "outputId": "c60abc28-27cb-4793-c5a8-492d7b67ec38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arr_temp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kzRL6QWemCP",
        "outputId": "59957ee6-56ca-4af4-d97c-27c41b157329"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[47.122   , 21.442009,  7.640007],\n",
              "        [47.122   , 21.442009,  7.640007],\n",
              "        [47.122   , 21.442009,  7.640007],\n",
              "        ...,\n",
              "        [47.122   , 21.442009,  7.640007],\n",
              "        [47.122   , 21.442009,  7.640007],\n",
              "        [47.122   , 21.442009,  7.640007]],\n",
              "\n",
              "       [[47.122   , 21.442009,  7.640007],\n",
              "        [47.122   , 21.442009,  7.640007],\n",
              "        [47.122   , 21.442009,  7.640007],\n",
              "        ...,\n",
              "        [47.122   , 21.442009,  7.640007],\n",
              "        [47.122   , 21.442009,  7.640007],\n",
              "        [47.122   , 21.442009,  7.640007]],\n",
              "\n",
              "       [[47.122   , 21.442009,  7.640007],\n",
              "        [47.122   , 21.442009,  7.640007],\n",
              "        [47.122   , 21.442009,  7.640007],\n",
              "        ...,\n",
              "        [47.122   , 21.442009,  7.640007],\n",
              "        [47.122   , 21.442009,  7.640007],\n",
              "        [47.122   , 21.442009,  7.640007]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[47.122   , 21.442009,  7.640007],\n",
              "        [47.122   , 21.442009,  7.640007],\n",
              "        [47.122   , 21.442009,  7.640007],\n",
              "        ...,\n",
              "        [47.122   , 21.442009,  7.640007],\n",
              "        [47.122   , 21.442009,  7.640007],\n",
              "        [47.122   , 21.442009,  7.640007]],\n",
              "\n",
              "       [[47.122   , 21.442009,  7.640007],\n",
              "        [47.122   , 21.442009,  7.640007],\n",
              "        [47.122   , 21.442009,  7.640007],\n",
              "        ...,\n",
              "        [47.122   , 21.442009,  7.640007],\n",
              "        [47.122   , 21.442009,  7.640007],\n",
              "        [47.122   , 21.442009,  7.640007]],\n",
              "\n",
              "       [[47.122   , 21.442009,  7.640007],\n",
              "        [47.122   , 21.442009,  7.640007],\n",
              "        [47.122   , 21.442009,  7.640007],\n",
              "        ...,\n",
              "        [47.122   , 21.442009,  7.640007],\n",
              "        [47.122   , 21.442009,  7.640007],\n",
              "        [47.122   , 21.442009,  7.640007]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arr_temp.tolist()"
      ],
      "metadata": {
        "id": "f-waS7vuejIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train with Python Functions"
      ],
      "metadata": {
        "id": "EjWaeHhAoGDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert Spark DataFrame to Pandas DataFrame\n",
        "df_pictures = pictures_df.toPandas()\n",
        "\n",
        "# Isolate train dataset\n",
        "df_train = df_pictures[df_pictures['dataset'] == 'Training']\n",
        "\n",
        "# Preprocess raw image bytes\n",
        "X_train = np.stack(df_train['content'].map(preprocess))\n",
        "print(\"Shape X_train: \", X_train.shape)\n",
        "\n",
        "y_train = df_train['target_code'].values\n",
        "\n",
        "# one-hot encoding using keras' numpy-related utilities\n",
        "print(\"Shape y_train before one-hot encoding: \", y_train.shape)\n",
        "Y_train = np_utils.to_categorical(y_train, 25)\n",
        "print(\"Shape Y_train after one-hot encoding: \", Y_train.shape)"
      ],
      "metadata": {
        "id": "0_QUdJEFhp8P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a6824e0-ac71-4dda-8d60-cc986519081e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape X_train:  (97, 224, 224, 3)\n",
            "Shape y_train before one-hot encoding:  (97,)\n",
            "Shape Y_train after one-hot encoding:  (97, 25)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train new_model with Training dataset\n",
        "EARLY_STOP_PATIENCE = 10  # EARLY_STOP_PATIENCE must be < NUM_EPOCHS\n",
        "cb_early_stopper = EarlyStopping(monitor = 'loss', patience = EARLY_STOP_PATIENCE)\n",
        "\n",
        "cb_checkpointer = ModelCheckpoint(filepath = 'best.hdf5', monitor = 'loss', save_best_only = True, mode = 'auto')\n",
        "\n",
        "NUM_EPOCHS = 30\n",
        "preds = new_model.fit(x=X_train, y=Y_train, epochs=NUM_EPOCHS, callbacks=[cb_checkpointer, cb_early_stopper])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iAz4kwoi6SC",
        "outputId": "7ccbbe9d-add8-4640-cf11-62fdab2c4828"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "4/4 [==============================] - 18s 4s/step - loss: 670.0675 - accuracy: 0.0619\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 16s 4s/step - loss: 1093.9584 - accuracy: 0.2474\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 17s 4s/step - loss: 114.9367 - accuracy: 0.3608\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 17s 4s/step - loss: 67.5636 - accuracy: 0.3918\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 17s 4s/step - loss: 2.5487 - accuracy: 0.4536\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 16s 4s/step - loss: 3.3675 - accuracy: 0.4227\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 16s 4s/step - loss: 7.1960 - accuracy: 0.4433\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 16s 4s/step - loss: 3.5551 - accuracy: 0.4536\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_model.save(OUTPUT+\"/fruits-360_transferlearning_restnet50.h5\")"
      ],
      "metadata": {
        "id": "HnNiyeC_HITi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict fruit class with my new model on Test dataset <a class=\"anchor\" id=\"sub8_3\"></a> "
      ],
      "metadata": {
        "id": "4JfCixevYzl_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Isolate test dataset\n",
        "df_test = df_pictures[df_pictures['dataset'] == 'Test']\n",
        "\n",
        "# Preprocess raw image bytes\n",
        "X_test = np.stack(df_test['content'].map(preprocess))\n",
        "print(\"Shape X_test: \", X_test.shape)\n",
        "\n",
        "# Compute target probabilities\n",
        "Y_test_pred = new_model.predict(X_test)\n",
        "print(\"Shape Y_test_pred: \", Y_test_pred.shape)\n",
        "\n",
        "# Deduct target prediction\n",
        "y_test_pred = np.argmax(Y_test_pred, axis=1)\n",
        "print(\"Shape y_test_pred: \", y_test_pred.shape)"
      ],
      "metadata": {
        "id": "5-l23wzvOdFp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72824524-2299-4d24-a3d3-06ef358a49e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape X_test:  (48, 224, 224, 3)\n",
            "Shape Y_test_pred:  (48, 25)\n",
            "Shape y_test_pred:  (48,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualise classification results <a class=\"anchor\" id=\"chapter9\"></a> "
      ],
      "metadata": {
        "id": "tTuKoD9CY7Od"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_final = final_df.toPandas()\n",
        "\n",
        "# Isolate Test dataset\n",
        "df_test = df_final[df_final['dataset'] == 'Test']\n",
        "\n",
        "# Transform to Array\n",
        "X_test_pca = np.stack(df_test['X_vectors_pca'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03FCuhPBIFOz",
        "outputId": "3f6b5ecc-11c8-4124-b6a4-281ceb87b513"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyspark/sql/pandas/conversion.py:87: UserWarning: toPandas attempted Arrow optimization because 'spark.sql.execution.arrow.pyspark.enabled' is set to true; however, failed by the reason below:\n",
            "  Unsupported type in conversion to Arrow: VectorUDT\n",
            "Attempting non-optimization as 'spark.sql.execution.arrow.pyspark.fallback.enabled' is set to true.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(10, 8))\n",
        "\n",
        "# Draw predictions in the first main plan\n",
        "plt.scatter(X_test_pca[:, 0], X_test_pca[:, 1], s=10, c=y_test_pred+1)\n",
        "plt.colorbar()\n",
        "\n",
        "plt.plot([X_test_pca[:, 0].min(), X_test_pca[:, 0].max()], [0, 0], color='grey', ls='-') \n",
        "plt.plot([0, 0], [X_test_pca[:, 1].min(), X_test_pca[:, 1].max()], color='grey', ls='-') \n",
        "\n",
        "plt.title(\"Projection of predictions on the first main plan\")\n",
        "plt.xlabel(\"PC1\")\n",
        "plt.ylabel(\"PC2\")   \n",
        "   \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "04i1fs_uylSU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "9ae0b878-74fe-4ded-a48a-941804cb9149"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "a7e9a1149953069853d4d83ec46f22084dce8711",
        "collapsed": true,
        "id": "nyxppMvPi_Da"
      },
      "source": [
        "* [Go to Table des matières](#chapter0)\n",
        "\n",
        "# End <a class=\"anchor\" id=\"chapter100\"></a> "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "P8_05_notebook_cloud.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Ghpp_J6ai_DR",
        "YLmjU2qkNU7a",
        "-rF8OT-7i_DU",
        "bgnwTt6ri_DX",
        "JiLzKEFLnu8z",
        "tTuKoD9CY7Od"
      ],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}